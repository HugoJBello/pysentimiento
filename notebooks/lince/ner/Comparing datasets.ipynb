{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Son iguales los datasets de huggingface y los .conll?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset lince (/home/jmperez/.cache/huggingface/datasets/lince/ner_spaeng/1.0.0/10d41747f55f0849fa84ac579ea1acfa7df49aa2015b60426bc459c111b3d589)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98677a157b7d4004a355c0f942981e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jmperez/.cache/huggingface/datasets/lince/ner_spaeng/1.0.0/10d41747f55f0849fa84ac579ea1acfa7df49aa2015b60426bc459c111b3d589/cache-f749fd5ca349b1d8.arrow\n",
      "Loading cached processed dataset at /home/jmperez/.cache/huggingface/datasets/lince/ner_spaeng/1.0.0/10d41747f55f0849fa84ac579ea1acfa7df49aa2015b60426bc459c111b3d589/cache-875716555d36ff1f.arrow\n",
      "Loading cached processed dataset at /home/jmperez/.cache/huggingface/datasets/lince/ner_spaeng/1.0.0/10d41747f55f0849fa84ac579ea1acfa7df49aa2015b60426bc459c111b3d589/cache-1afcf30fe2e4ebdb.arrow\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import DatasetDict, Dataset\n",
    "from pysentimiento.lince.ner import load_datasets, load_conll\n",
    "\n",
    "train_dataset, dev_dataset, test_dataset = load_datasets(\"es\", preprocess=False)\n",
    "\n",
    "lince_ner = DatasetDict(\n",
    "    train=train_dataset,\n",
    "    validation=dev_dataset,\n",
    "    test=test_dataset,\n",
    ")\n",
    "\n",
    "def load_dataset_from_conll(path):\n",
    "    data = load_conll(path)\n",
    "    words = [[x[0] for x in sentence] for sentence in data]\n",
    "    langs = [[x[1] for x in sentence] for sentence in data]\n",
    "    if len(data[0][0]) == 2:\n",
    "        ner = [[None] * len(x) for x in data]\n",
    "    else:\n",
    "        ner = [[x[2] for x in sentence] for sentence in data]\n",
    "\n",
    "    ## Sanity Check\n",
    "    for w, l in zip(words, ner):\n",
    "        assert len(w) == len(l)\n",
    "    \n",
    "    return Dataset.from_dict({\n",
    "        \"words\": words,\n",
    "        \"lang\": langs,\n",
    "        \"ner\": ner,\n",
    "    })\n",
    "\n",
    "\n",
    "orig = DatasetDict(\n",
    "    train=load_dataset_from_conll(\"../../../data/lince/ner_spaeng/train.conll\"),\n",
    "    validation=load_dataset_from_conll(\"../../../data/lince/ner_spaeng/dev.conll\"),\n",
    "    test=load_dataset_from_conll(\"../../../data/lince/ner_spaeng/test.conll\"),\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a72768a5f04ef5932f172773327222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39591cb3479246a6881717b374cfc600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca0718ee6f34386a971a0f2872e18dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23527 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 problematic examples\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "problematic = []\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "\n",
    "    assert len(lince_ner[split]) == len(orig[split])\n",
    "    for idx, (ex, orig_ex) in tqdm(enumerate(zip(lince_ner[split], orig[split])), total=len(lince_ner[split])):\n",
    "        if not ex[\"words\"] == orig_ex[\"words\"]:\n",
    "            problematic.append(idx)\n",
    "\n",
    "print(f\"{len(problematic)} problematic examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo bien jefe!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "387abc9bc94d8eb1bd0148a5d4cb2bf99bc3b40fa501b808e2b508b4f65ed831"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('pysentimiento-bwlKzHxB-py3.7': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
