{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "../evaluations/sentiment_beto.json\n",
      "../evaluations/sentiment_roberta_base.json\n",
      "../evaluations/sentiment_bert_base.json\n",
      "../evaluations/sentiment_distilbert_es.json\n",
      "../evaluations/sentiment_bertweet_base.json\n",
      "../evaluations/sentiment_mbert_es.json\n",
      "../evaluations/sentiment_distilbert_en.json\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import glob \n",
    "import json \n",
    "\n",
    "evaluation_files = glob.glob(\"../evaluations/sentiment_*.json\")\n",
    "\n",
    "evaluations = []\n",
    "\n",
    "for file in evaluation_files:\n",
    "    print(file)\n",
    "    with open(file) as f:\n",
    "        evaluation = json.load(f)\n",
    "        evaluation[\"file\"] = file.split(\"/\")[-1]\n",
    "        evaluations.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Lang</th>\n      <th>Model</th>\n      <th>Loss</th>\n      <th>Neg f1</th>\n      <th>Neg precision</th>\n      <th>Neg recall</th>\n      <th>Neu f1</th>\n      <th>Neu precision</th>\n      <th>Neu recall</th>\n      <th>Pos f1</th>\n      <th>Pos precision</th>\n      <th>Pos recall</th>\n      <th>Macro f1</th>\n      <th>Macro precision</th>\n      <th>Macro recall</th>\n      <th>Acc</th>\n      <th>Runtime</th>\n      <th>Samples per second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>en</td>\n      <td>distilbert-en</td>\n      <td>0.492271</td>\n      <td>0.749726</td>\n      <td>0.757423</td>\n      <td>0.742185</td>\n      <td>0.821287</td>\n      <td>0.799908</td>\n      <td>0.843841</td>\n      <td>0.815571</td>\n      <td>0.846858</td>\n      <td>0.786514</td>\n      <td>0.795528</td>\n      <td>0.801396</td>\n      <td>0.790847</td>\n      <td>0.808307</td>\n      <td>70.8846</td>\n      <td>291.065</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>en</td>\n      <td>bert-base</td>\n      <td>0.377735</td>\n      <td>0.824151</td>\n      <td>0.804361</td>\n      <td>0.844940</td>\n      <td>0.852689</td>\n      <td>0.885212</td>\n      <td>0.822471</td>\n      <td>0.864924</td>\n      <td>0.832612</td>\n      <td>0.899844</td>\n      <td>0.847255</td>\n      <td>0.840728</td>\n      <td>0.855752</td>\n      <td>0.852462</td>\n      <td>111.3789</td>\n      <td>185.242</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>en</td>\n      <td>roberta-base</td>\n      <td>0.267115</td>\n      <td>0.901743</td>\n      <td>0.876204</td>\n      <td>0.928815</td>\n      <td>0.923145</td>\n      <td>0.937930</td>\n      <td>0.908818</td>\n      <td>0.928747</td>\n      <td>0.920540</td>\n      <td>0.937102</td>\n      <td>0.917878</td>\n      <td>0.911558</td>\n      <td>0.924911</td>\n      <td>0.921627</td>\n      <td>106.1283</td>\n      <td>194.406</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>en</td>\n      <td>bertweet-base</td>\n      <td>0.268181</td>\n      <td>0.910097</td>\n      <td>0.880718</td>\n      <td>0.941504</td>\n      <td>0.930614</td>\n      <td>0.946143</td>\n      <td>0.915587</td>\n      <td>0.936960</td>\n      <td>0.929707</td>\n      <td>0.944326</td>\n      <td>0.925890</td>\n      <td>0.918856</td>\n      <td>0.933806</td>\n      <td>0.929478</td>\n      <td>110.3031</td>\n      <td>187.048</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>es</td>\n      <td>distilbert-es</td>\n      <td>0.975005</td>\n      <td>0.649262</td>\n      <td>0.689484</td>\n      <td>0.613474</td>\n      <td>0.479947</td>\n      <td>0.421640</td>\n      <td>0.556968</td>\n      <td>0.667876</td>\n      <td>0.717836</td>\n      <td>0.624417</td>\n      <td>0.599028</td>\n      <td>0.609653</td>\n      <td>0.598286</td>\n      <td>0.601735</td>\n      <td>23.6880</td>\n      <td>306.653</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>es</td>\n      <td>mbert-es</td>\n      <td>1.359172</td>\n      <td>0.667889</td>\n      <td>0.724344</td>\n      <td>0.619599</td>\n      <td>0.475637</td>\n      <td>0.424242</td>\n      <td>0.541200</td>\n      <td>0.669420</td>\n      <td>0.686887</td>\n      <td>0.652819</td>\n      <td>0.604315</td>\n      <td>0.611824</td>\n      <td>0.604539</td>\n      <td>0.609169</td>\n      <td>37.1661</td>\n      <td>195.447</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>es</td>\n      <td>beto</td>\n      <td>1.462894</td>\n      <td>0.728972</td>\n      <td>0.772571</td>\n      <td>0.690031</td>\n      <td>0.535633</td>\n      <td>0.483607</td>\n      <td>0.600203</td>\n      <td>0.734971</td>\n      <td>0.761710</td>\n      <td>0.710047</td>\n      <td>0.666526</td>\n      <td>0.672629</td>\n      <td>0.666760</td>\n      <td>0.672219</td>\n      <td>41.9681</td>\n      <td>173.084</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Lang          Model      Loss    Neg f1  Neg precision  Neg recall  \\\n6   en  distilbert-en  0.492271  0.749726       0.757423    0.742185   \n2   en      bert-base  0.377735  0.824151       0.804361    0.844940   \n1   en   roberta-base  0.267115  0.901743       0.876204    0.928815   \n4   en  bertweet-base  0.268181  0.910097       0.880718    0.941504   \n3   es  distilbert-es  0.975005  0.649262       0.689484    0.613474   \n5   es       mbert-es  1.359172  0.667889       0.724344    0.619599   \n0   es           beto  1.462894  0.728972       0.772571    0.690031   \n\n     Neu f1  Neu precision  Neu recall    Pos f1  Pos precision  Pos recall  \\\n6  0.821287       0.799908    0.843841  0.815571       0.846858    0.786514   \n2  0.852689       0.885212    0.822471  0.864924       0.832612    0.899844   \n1  0.923145       0.937930    0.908818  0.928747       0.920540    0.937102   \n4  0.930614       0.946143    0.915587  0.936960       0.929707    0.944326   \n3  0.479947       0.421640    0.556968  0.667876       0.717836    0.624417   \n5  0.475637       0.424242    0.541200  0.669420       0.686887    0.652819   \n0  0.535633       0.483607    0.600203  0.734971       0.761710    0.710047   \n\n   Macro f1  Macro precision  Macro recall       Acc   Runtime  \\\n6  0.795528         0.801396      0.790847  0.808307   70.8846   \n2  0.847255         0.840728      0.855752  0.852462  111.3789   \n1  0.917878         0.911558      0.924911  0.921627  106.1283   \n4  0.925890         0.918856      0.933806  0.929478  110.3031   \n3  0.599028         0.609653      0.598286  0.601735   23.6880   \n5  0.604315         0.611824      0.604539  0.609169   37.1661   \n0  0.666526         0.672629      0.666760  0.672219   41.9681   \n\n   Samples per second  \n6             291.065  \n2             185.242  \n1             194.406  \n4             187.048  \n3             306.653  \n5             195.447  \n0             173.084  "
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {**evaluation, **evaluation[\"metrics\"]} for evaluation in evaluations\n",
    "])\n",
    "\n",
    "df.drop(labels=[\"predictions\", \"labels\", \"metrics\", \"file\"], inplace=True, axis=1)\n",
    "df[\"model\"] = df[\"model\"].str.replace(\"models/\", \"\")\n",
    "df[\"model\"] = df[\"model\"].str.replace(\"-sentiment-analysis/\", \"\")\n",
    "df.columns = [col.replace(\"test_\", \"\").replace(\"_\", \" \").capitalize() for col in df.columns]\n",
    "#df.set_index(\"Model\", inplace=True)\n",
    "df = df.sort_values([\"Lang\", \"Macro f1\"]) \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "        Model & Lang &  Neg f1 &  Pos f1 &  Neu f1 &  Macro f1 \\\\\n",
      "\\midrule\n",
      "distilbert-en &   en &   0.750 &   0.816 &   0.821 &     0.796 \\\\\n",
      "    bert-base &   en &   0.824 &   0.865 &   0.853 &     0.847 \\\\\n",
      " roberta-base &   en &   0.902 &   0.929 &   0.923 &     0.918 \\\\\n",
      "bertweet-base &   en &   0.910 &   0.937 &   0.931 &     0.926 \\\\\n",
      "distilbert-es &   es &   0.649 &   0.668 &   0.480 &     0.599 \\\\\n",
      "     mbert-es &   es &   0.668 &   0.669 &   0.476 &     0.604 \\\\\n",
      "         beto &   es &   0.729 &   0.735 &   0.536 &     0.667 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"Model\", \"Lang\", \"Neg f1\", \"Pos f1\", \"Neu f1\", \"Macro f1\"]].to_latex(index=False, float_format=\"{0:.3f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[[\"lang\", \"test_neg_f1\", \"test_pos_f1\", \"test_neu_f1\", \"test_macro_f1\"]].to_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pysent-oyXQVI9B': pipenv)",
   "name": "python385jvsc74a57bd01b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "1b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}