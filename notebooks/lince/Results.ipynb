{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "def clean_key(k):\n",
    "    return k.split(\"_\", 1)[1]\n",
    "\n",
    "base_path = \"../../evaluations/lince/ner/dev/\"\n",
    "\n",
    "evaluation_paths = glob.glob(f\"{base_path}/*.json\")\n",
    "\n",
    "models = {}\n",
    "\n",
    "for path in evaluation_paths:\n",
    "    name = os.path.basename(path).split(\".\")[0]\n",
    "    with open(path) as f:\n",
    "        model_evaluation = json.load(f)\n",
    "        clean_evaluations = []\n",
    "        for task in model_evaluation[\"evaluations\"].keys():\n",
    "            task_evaluations = model_evaluation[\"evaluations\"][task]\n",
    "            clean_evaluations = [\n",
    "                {clean_key(k): v for k, v in ev.items()} \n",
    "                for ev in task_evaluations\n",
    "            ]\n",
    "\n",
    "            model_evaluation[\"evaluations\"][task] = clean_evaluations\n",
    "        models[name] = model_evaluation\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "bert-base-cased\n",
      "ner\n",
      "5\n",
      "==================================================\n",
      "xlm-roberta-base_nosublabeling_emojis\n",
      "ner\n",
      "1\n",
      "==================================================\n",
      "xlm-roberta-base\n",
      "ner\n",
      "2\n",
      "==================================================\n",
      "bert-base-multilingual-uncased\n",
      "ner\n",
      "2\n",
      "==================================================\n",
      "bert-base-spanish-wwm-uncased\n",
      "ner\n",
      "4\n",
      "==================================================\n",
      "robertuito-base-uncased_nosublabeling_emojis\n",
      "ner\n",
      "2\n",
      "==================================================\n",
      "xlm-roberta-base_nosublabeling\n",
      "ner\n",
      "2\n",
      "==================================================\n",
      "robertuito-base-uncased\n",
      "ner\n",
      "6\n",
      "==================================================\n",
      "robertuito-base-deacc\n",
      "ner\n",
      "5\n",
      "==================================================\n",
      "robertuito-base-cased\n",
      "ner\n",
      "7\n",
      "==================================================\n",
      "robertuito-base-deacc_nosublabeling\n",
      "ner\n",
      "5\n",
      "==================================================\n",
      "bert-base-uncased\n",
      "ner\n",
      "5\n",
      "==================================================\n",
      "bert-base-multilingual-uncased_nosublabeling_emojis\n",
      "ner\n",
      "3\n",
      "==================================================\n",
      "robertuito-base-cased_nosublabeling_emojis\n",
      "ner\n",
      "2\n",
      "==================================================\n",
      "robertuito-base-deacc_nosublabeling_emojis\n",
      "ner\n",
      "2\n",
      "==================================================\n",
      "bert-base-multilingual-uncased_nosublabeling\n",
      "ner\n",
      "4\n",
      "==================================================\n",
      "robertuito-base-uncased_nosublabeling\n",
      "ner\n",
      "5\n",
      "==================================================\n",
      "bert-base-spanish-wwm-cased\n",
      "ner\n",
      "1\n",
      "==================================================\n",
      "robertuito-base-cased_nosublabeling\n",
      "ner\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "\n",
    "for model, model_evaluation in models.items():\n",
    "    print(\"=\"*50)\n",
    "    print(model)\n",
    "    for task, task_evaluations in model_evaluation[\"evaluations\"].items():\n",
    "        print(task)\n",
    "        print(len(task_evaluations))\n",
    "        for evaluation in task_evaluations:\n",
    "\n",
    "            results.append({\n",
    "                **{\n",
    "                    \"model\": model,\n",
    "                    \"task\": task,\n",
    "                },\n",
    "                **evaluation,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert-base-cased</th>\n",
       "      <td>0.554 ± 0.004</td>\n",
       "      <td>0.406 ± 0.006</td>\n",
       "      <td>0.979 ± 0.0</td>\n",
       "      <td>0.544 ± 0.008</td>\n",
       "      <td>0.564 ± 0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased</th>\n",
       "      <td>0.624 ± 0.005</td>\n",
       "      <td>0.481 ± 0.014</td>\n",
       "      <td>0.983 ± 0.001</td>\n",
       "      <td>0.604 ± 0.006</td>\n",
       "      <td>0.646 ± 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased_nosublabeling</th>\n",
       "      <td>0.653 ± 0.002</td>\n",
       "      <td>0.51 ± 0.007</td>\n",
       "      <td>0.985 ± 0.0</td>\n",
       "      <td>0.65 ± 0.006</td>\n",
       "      <td>0.656 ± 0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased_nosublabeling_emojis</th>\n",
       "      <td>0.649 ± 0.002</td>\n",
       "      <td>0.515 ± 0.008</td>\n",
       "      <td>0.985 ± 0.0</td>\n",
       "      <td>0.645 ± 0.002</td>\n",
       "      <td>0.653 ± 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-spanish-wwm-cased</th>\n",
       "      <td>0.566 ± nan</td>\n",
       "      <td>0.414 ± nan</td>\n",
       "      <td>0.977 ± nan</td>\n",
       "      <td>0.557 ± nan</td>\n",
       "      <td>0.576 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-spanish-wwm-uncased</th>\n",
       "      <td>0.605 ± 0.004</td>\n",
       "      <td>0.456 ± 0.004</td>\n",
       "      <td>0.981 ± 0.0</td>\n",
       "      <td>0.597 ± 0.008</td>\n",
       "      <td>0.613 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased</th>\n",
       "      <td>0.587 ± 0.005</td>\n",
       "      <td>0.436 ± 0.004</td>\n",
       "      <td>0.983 ± 0.0</td>\n",
       "      <td>0.578 ± 0.007</td>\n",
       "      <td>0.596 ± 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-cased</th>\n",
       "      <td>0.63 ± 0.004</td>\n",
       "      <td>0.47 ± 0.008</td>\n",
       "      <td>0.98 ± 0.0</td>\n",
       "      <td>0.608 ± 0.008</td>\n",
       "      <td>0.654 ± 0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-cased_nosublabeling</th>\n",
       "      <td>0.666 ± 0.003</td>\n",
       "      <td>0.51 ± 0.011</td>\n",
       "      <td>0.986 ± 0.0</td>\n",
       "      <td>0.656 ± 0.007</td>\n",
       "      <td>0.676 ± 0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-cased_nosublabeling_emojis</th>\n",
       "      <td>0.665 ± 0.001</td>\n",
       "      <td>0.513 ± 0.003</td>\n",
       "      <td>0.986 ± 0.0</td>\n",
       "      <td>0.646 ± 0.006</td>\n",
       "      <td>0.686 ± 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-deacc</th>\n",
       "      <td>0.647 ± 0.001</td>\n",
       "      <td>0.494 ± 0.009</td>\n",
       "      <td>0.982 ± 0.0</td>\n",
       "      <td>0.628 ± 0.003</td>\n",
       "      <td>0.667 ± 0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-deacc_nosublabeling</th>\n",
       "      <td>0.673 ± 0.004</td>\n",
       "      <td>0.523 ± 0.007</td>\n",
       "      <td>0.986 ± 0.0</td>\n",
       "      <td>0.666 ± 0.003</td>\n",
       "      <td>0.679 ± 0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-deacc_nosublabeling_emojis</th>\n",
       "      <td>0.67 ± 0.005</td>\n",
       "      <td>0.523 ± 0.001</td>\n",
       "      <td>0.986 ± 0.0</td>\n",
       "      <td>0.667 ± 0.007</td>\n",
       "      <td>0.673 ± 0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-uncased</th>\n",
       "      <td>0.649 ± 0.002</td>\n",
       "      <td>0.491 ± 0.005</td>\n",
       "      <td>0.982 ± 0.0</td>\n",
       "      <td>0.637 ± 0.009</td>\n",
       "      <td>0.662 ± 0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-uncased_nosublabeling</th>\n",
       "      <td>0.668 ± 0.003</td>\n",
       "      <td>0.507 ± 0.004</td>\n",
       "      <td>0.986 ± 0.0</td>\n",
       "      <td>0.667 ± 0.007</td>\n",
       "      <td>0.668 ± 0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-uncased_nosublabeling_emojis</th>\n",
       "      <td>0.668 ± 0.006</td>\n",
       "      <td>0.509 ± 0.01</td>\n",
       "      <td>0.986 ± 0.0</td>\n",
       "      <td>0.666 ± 0.005</td>\n",
       "      <td>0.669 ± 0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-roberta-base</th>\n",
       "      <td>0.614 ± 0.001</td>\n",
       "      <td>0.467 ± 0.005</td>\n",
       "      <td>0.981 ± 0.0</td>\n",
       "      <td>0.601 ± 0.0</td>\n",
       "      <td>0.627 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-roberta-base_nosublabeling</th>\n",
       "      <td>0.63 ± 0.0</td>\n",
       "      <td>0.49 ± 0.001</td>\n",
       "      <td>0.985 ± 0.0</td>\n",
       "      <td>0.629 ± 0.001</td>\n",
       "      <td>0.631 ± 0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-roberta-base_nosublabeling_emojis</th>\n",
       "      <td>0.638 ± nan</td>\n",
       "      <td>0.494 ± nan</td>\n",
       "      <td>0.985 ± nan</td>\n",
       "      <td>0.638 ± nan</td>\n",
       "      <td>0.638 ± nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         micro_f1  \\\n",
       "model                                                               \n",
       "bert-base-cased                                     0.554 ± 0.004   \n",
       "bert-base-multilingual-uncased                      0.624 ± 0.005   \n",
       "bert-base-multilingual-uncased_nosublabeling        0.653 ± 0.002   \n",
       "bert-base-multilingual-uncased_nosublabeling_em...  0.649 ± 0.002   \n",
       "bert-base-spanish-wwm-cased                           0.566 ± nan   \n",
       "bert-base-spanish-wwm-uncased                       0.605 ± 0.004   \n",
       "bert-base-uncased                                   0.587 ± 0.005   \n",
       "robertuito-base-cased                                0.63 ± 0.004   \n",
       "robertuito-base-cased_nosublabeling                 0.666 ± 0.003   \n",
       "robertuito-base-cased_nosublabeling_emojis          0.665 ± 0.001   \n",
       "robertuito-base-deacc                               0.647 ± 0.001   \n",
       "robertuito-base-deacc_nosublabeling                 0.673 ± 0.004   \n",
       "robertuito-base-deacc_nosublabeling_emojis           0.67 ± 0.005   \n",
       "robertuito-base-uncased                             0.649 ± 0.002   \n",
       "robertuito-base-uncased_nosublabeling               0.668 ± 0.003   \n",
       "robertuito-base-uncased_nosublabeling_emojis        0.668 ± 0.006   \n",
       "xlm-roberta-base                                    0.614 ± 0.001   \n",
       "xlm-roberta-base_nosublabeling                         0.63 ± 0.0   \n",
       "xlm-roberta-base_nosublabeling_emojis                 0.638 ± nan   \n",
       "\n",
       "                                                         macro_f1  \\\n",
       "model                                                               \n",
       "bert-base-cased                                     0.406 ± 0.006   \n",
       "bert-base-multilingual-uncased                      0.481 ± 0.014   \n",
       "bert-base-multilingual-uncased_nosublabeling         0.51 ± 0.007   \n",
       "bert-base-multilingual-uncased_nosublabeling_em...  0.515 ± 0.008   \n",
       "bert-base-spanish-wwm-cased                           0.414 ± nan   \n",
       "bert-base-spanish-wwm-uncased                       0.456 ± 0.004   \n",
       "bert-base-uncased                                   0.436 ± 0.004   \n",
       "robertuito-base-cased                                0.47 ± 0.008   \n",
       "robertuito-base-cased_nosublabeling                  0.51 ± 0.011   \n",
       "robertuito-base-cased_nosublabeling_emojis          0.513 ± 0.003   \n",
       "robertuito-base-deacc                               0.494 ± 0.009   \n",
       "robertuito-base-deacc_nosublabeling                 0.523 ± 0.007   \n",
       "robertuito-base-deacc_nosublabeling_emojis          0.523 ± 0.001   \n",
       "robertuito-base-uncased                             0.491 ± 0.005   \n",
       "robertuito-base-uncased_nosublabeling               0.507 ± 0.004   \n",
       "robertuito-base-uncased_nosublabeling_emojis         0.509 ± 0.01   \n",
       "xlm-roberta-base                                    0.467 ± 0.005   \n",
       "xlm-roberta-base_nosublabeling                       0.49 ± 0.001   \n",
       "xlm-roberta-base_nosublabeling_emojis                 0.494 ± nan   \n",
       "\n",
       "                                                         accuracy  \\\n",
       "model                                                               \n",
       "bert-base-cased                                       0.979 ± 0.0   \n",
       "bert-base-multilingual-uncased                      0.983 ± 0.001   \n",
       "bert-base-multilingual-uncased_nosublabeling          0.985 ± 0.0   \n",
       "bert-base-multilingual-uncased_nosublabeling_em...    0.985 ± 0.0   \n",
       "bert-base-spanish-wwm-cased                           0.977 ± nan   \n",
       "bert-base-spanish-wwm-uncased                         0.981 ± 0.0   \n",
       "bert-base-uncased                                     0.983 ± 0.0   \n",
       "robertuito-base-cased                                  0.98 ± 0.0   \n",
       "robertuito-base-cased_nosublabeling                   0.986 ± 0.0   \n",
       "robertuito-base-cased_nosublabeling_emojis            0.986 ± 0.0   \n",
       "robertuito-base-deacc                                 0.982 ± 0.0   \n",
       "robertuito-base-deacc_nosublabeling                   0.986 ± 0.0   \n",
       "robertuito-base-deacc_nosublabeling_emojis            0.986 ± 0.0   \n",
       "robertuito-base-uncased                               0.982 ± 0.0   \n",
       "robertuito-base-uncased_nosublabeling                 0.986 ± 0.0   \n",
       "robertuito-base-uncased_nosublabeling_emojis          0.986 ± 0.0   \n",
       "xlm-roberta-base                                      0.981 ± 0.0   \n",
       "xlm-roberta-base_nosublabeling                        0.985 ± 0.0   \n",
       "xlm-roberta-base_nosublabeling_emojis                 0.985 ± nan   \n",
       "\n",
       "                                                        precision  \\\n",
       "model                                                               \n",
       "bert-base-cased                                     0.544 ± 0.008   \n",
       "bert-base-multilingual-uncased                      0.604 ± 0.006   \n",
       "bert-base-multilingual-uncased_nosublabeling         0.65 ± 0.006   \n",
       "bert-base-multilingual-uncased_nosublabeling_em...  0.645 ± 0.002   \n",
       "bert-base-spanish-wwm-cased                           0.557 ± nan   \n",
       "bert-base-spanish-wwm-uncased                       0.597 ± 0.008   \n",
       "bert-base-uncased                                   0.578 ± 0.007   \n",
       "robertuito-base-cased                               0.608 ± 0.008   \n",
       "robertuito-base-cased_nosublabeling                 0.656 ± 0.007   \n",
       "robertuito-base-cased_nosublabeling_emojis          0.646 ± 0.006   \n",
       "robertuito-base-deacc                               0.628 ± 0.003   \n",
       "robertuito-base-deacc_nosublabeling                 0.666 ± 0.003   \n",
       "robertuito-base-deacc_nosublabeling_emojis          0.667 ± 0.007   \n",
       "robertuito-base-uncased                             0.637 ± 0.009   \n",
       "robertuito-base-uncased_nosublabeling               0.667 ± 0.007   \n",
       "robertuito-base-uncased_nosublabeling_emojis        0.666 ± 0.005   \n",
       "xlm-roberta-base                                      0.601 ± 0.0   \n",
       "xlm-roberta-base_nosublabeling                      0.629 ± 0.001   \n",
       "xlm-roberta-base_nosublabeling_emojis                 0.638 ± nan   \n",
       "\n",
       "                                                           recall  \n",
       "model                                                              \n",
       "bert-base-cased                                     0.564 ± 0.006  \n",
       "bert-base-multilingual-uncased                      0.646 ± 0.017  \n",
       "bert-base-multilingual-uncased_nosublabeling        0.656 ± 0.008  \n",
       "bert-base-multilingual-uncased_nosublabeling_em...  0.653 ± 0.005  \n",
       "bert-base-spanish-wwm-cased                           0.576 ± nan  \n",
       "bert-base-spanish-wwm-uncased                       0.613 ± 0.002  \n",
       "bert-base-uncased                                   0.596 ± 0.005  \n",
       "robertuito-base-cased                               0.654 ± 0.008  \n",
       "robertuito-base-cased_nosublabeling                 0.676 ± 0.004  \n",
       "robertuito-base-cased_nosublabeling_emojis          0.686 ± 0.005  \n",
       "robertuito-base-deacc                               0.667 ± 0.004  \n",
       "robertuito-base-deacc_nosublabeling                 0.679 ± 0.006  \n",
       "robertuito-base-deacc_nosublabeling_emojis          0.673 ± 0.003  \n",
       "robertuito-base-uncased                             0.662 ± 0.009  \n",
       "robertuito-base-uncased_nosublabeling               0.668 ± 0.004  \n",
       "robertuito-base-uncased_nosublabeling_emojis        0.669 ± 0.007  \n",
       "xlm-roberta-base                                    0.627 ± 0.002  \n",
       "xlm-roberta-base_nosublabeling                      0.631 ± 0.002  \n",
       "xlm-roberta-base_nosublabeling_emojis                 0.638 ± nan  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "mean_df = pd.DataFrame(results).groupby([\"model\"]).mean()\n",
    "std_df = pd.DataFrame(results).groupby([\"model\"]).std()\n",
    "# Magia negra\n",
    "\n",
    "#mean_df = mean_df.unstack(1)\n",
    "#std_df = std_df.unstack(1)\n",
    "\n",
    "cols = [\"micro_f1\", \"macro_f1\", \"accuracy\", \"precision\", \"recall\"]\n",
    "\n",
    "idx = mean_df.index\n",
    "\n",
    "mean_df.loc[idx, cols].round(3).astype(str) + \" ± \" + std_df.loc[idx, cols].round(3).astype(str)\n",
    "\n",
    "#mean_df.loc[idx, cols].sort_values(by=[\"micro_f1\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>robertuito-base-deacc_nosublabeling</th>\n",
       "      <td>0.673</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-deacc_nosublabeling_emojis</th>\n",
       "      <td>0.670</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-uncased_nosublabeling_emojis</th>\n",
       "      <td>0.668</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-uncased_nosublabeling</th>\n",
       "      <td>0.668</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-cased_nosublabeling</th>\n",
       "      <td>0.666</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-cased_nosublabeling_emojis</th>\n",
       "      <td>0.665</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased_nosublabeling</th>\n",
       "      <td>0.653</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-uncased</th>\n",
       "      <td>0.649</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased_nosublabeling_emojis</th>\n",
       "      <td>0.649</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-deacc</th>\n",
       "      <td>0.647</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-roberta-base_nosublabeling_emojis</th>\n",
       "      <td>0.638</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-base-cased</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-roberta-base_nosublabeling</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased</th>\n",
       "      <td>0.624</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-roberta-base</th>\n",
       "      <td>0.614</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-spanish-wwm-uncased</th>\n",
       "      <td>0.605</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased</th>\n",
       "      <td>0.587</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-spanish-wwm-cased</th>\n",
       "      <td>0.566</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-cased</th>\n",
       "      <td>0.554</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    micro_f1  macro_f1  \\\n",
       "model                                                                    \n",
       "robertuito-base-deacc_nosublabeling                    0.673     0.523   \n",
       "robertuito-base-deacc_nosublabeling_emojis             0.670     0.523   \n",
       "robertuito-base-uncased_nosublabeling_emojis           0.668     0.509   \n",
       "robertuito-base-uncased_nosublabeling                  0.668     0.507   \n",
       "robertuito-base-cased_nosublabeling                    0.666     0.510   \n",
       "robertuito-base-cased_nosublabeling_emojis             0.665     0.513   \n",
       "bert-base-multilingual-uncased_nosublabeling           0.653     0.510   \n",
       "robertuito-base-uncased                                0.649     0.491   \n",
       "bert-base-multilingual-uncased_nosublabeling_em...     0.649     0.515   \n",
       "robertuito-base-deacc                                  0.647     0.494   \n",
       "xlm-roberta-base_nosublabeling_emojis                  0.638     0.494   \n",
       "robertuito-base-cased                                  0.630     0.470   \n",
       "xlm-roberta-base_nosublabeling                         0.630     0.490   \n",
       "bert-base-multilingual-uncased                         0.624     0.481   \n",
       "xlm-roberta-base                                       0.614     0.467   \n",
       "bert-base-spanish-wwm-uncased                          0.605     0.456   \n",
       "bert-base-uncased                                      0.587     0.436   \n",
       "bert-base-spanish-wwm-cased                            0.566     0.414   \n",
       "bert-base-cased                                        0.554     0.406   \n",
       "\n",
       "                                                    accuracy  precision  \\\n",
       "model                                                                     \n",
       "robertuito-base-deacc_nosublabeling                    0.986      0.666   \n",
       "robertuito-base-deacc_nosublabeling_emojis             0.986      0.667   \n",
       "robertuito-base-uncased_nosublabeling_emojis           0.986      0.666   \n",
       "robertuito-base-uncased_nosublabeling                  0.986      0.667   \n",
       "robertuito-base-cased_nosublabeling                    0.986      0.656   \n",
       "robertuito-base-cased_nosublabeling_emojis             0.986      0.646   \n",
       "bert-base-multilingual-uncased_nosublabeling           0.985      0.650   \n",
       "robertuito-base-uncased                                0.982      0.637   \n",
       "bert-base-multilingual-uncased_nosublabeling_em...     0.985      0.645   \n",
       "robertuito-base-deacc                                  0.982      0.628   \n",
       "xlm-roberta-base_nosublabeling_emojis                  0.985      0.638   \n",
       "robertuito-base-cased                                  0.980      0.608   \n",
       "xlm-roberta-base_nosublabeling                         0.985      0.629   \n",
       "bert-base-multilingual-uncased                         0.983      0.604   \n",
       "xlm-roberta-base                                       0.981      0.601   \n",
       "bert-base-spanish-wwm-uncased                          0.981      0.597   \n",
       "bert-base-uncased                                      0.983      0.578   \n",
       "bert-base-spanish-wwm-cased                            0.977      0.557   \n",
       "bert-base-cased                                        0.979      0.544   \n",
       "\n",
       "                                                    recall  \n",
       "model                                                       \n",
       "robertuito-base-deacc_nosublabeling                  0.679  \n",
       "robertuito-base-deacc_nosublabeling_emojis           0.673  \n",
       "robertuito-base-uncased_nosublabeling_emojis         0.669  \n",
       "robertuito-base-uncased_nosublabeling                0.668  \n",
       "robertuito-base-cased_nosublabeling                  0.676  \n",
       "robertuito-base-cased_nosublabeling_emojis           0.686  \n",
       "bert-base-multilingual-uncased_nosublabeling         0.656  \n",
       "robertuito-base-uncased                              0.662  \n",
       "bert-base-multilingual-uncased_nosublabeling_em...   0.653  \n",
       "robertuito-base-deacc                                0.667  \n",
       "xlm-roberta-base_nosublabeling_emojis                0.638  \n",
       "robertuito-base-cased                                0.654  \n",
       "xlm-roberta-base_nosublabeling                       0.631  \n",
       "bert-base-multilingual-uncased                       0.646  \n",
       "xlm-roberta-base                                     0.627  \n",
       "bert-base-spanish-wwm-uncased                        0.613  \n",
       "bert-base-uncased                                    0.596  \n",
       "bert-base-spanish-wwm-cased                          0.576  \n",
       "bert-base-cased                                      0.564  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df.loc[idx, cols].sort_values(by=[\"micro_f1\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "387abc9bc94d8eb1bd0148a5d4cb2bf99bc3b40fa501b808e2b508b4f65ed831"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('pysentimiento-bwlKzHxB-py3.7': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
