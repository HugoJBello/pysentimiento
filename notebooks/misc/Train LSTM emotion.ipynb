{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM model\n",
    "\n",
    "In this notebook we will train a LSTM model for Sentiment Analysis in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset, Value, ClassLabel, Features\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "from pysentimiento.emotion import load_datasets\n",
    "\n",
    "\n",
    "train_dataset, dev_dataset, test_dataset = load_datasets(preprocessing_args={\n",
    "    \"user_token\": \"USUARIO\",\n",
    "    \"url_token\": \"URL\",\n",
    "    \"hashtag_token\": \"hashtag\",\n",
    "    \"emoji_wrapper\": \"\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16313"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "import unidecode\n",
    "\n",
    "tokenizer = get_tokenizer(\"spacy\", \"es_core_news_sm\")\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "\"\"\"\n",
    "No overfitting, just taking the embeddings\n",
    "\"\"\"\n",
    "for dataset in [train_dataset, dev_dataset, test_dataset]:\n",
    "    for example in dataset:\n",
    "        tokens = tokenizer(unidecode.unidecode(example[\"text\"].lower()))\n",
    "        counter.update(tokens)\n",
    "\n",
    "# Meto todas\n",
    "vocab = Vocab(counter, min_freq=1)\n",
    "\n",
    "len(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a72dcdefafd470ea048b7b71c6c7503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5049.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c689a32a7a6d4b4fa9b05b433256e010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1683.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5446461f6a468b9192a1cc5a10f1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1677.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tokenize(batch):\n",
    "    text = unidecode.unidecode(batch['text'].lower())\n",
    "    tokens = tokenizer(text)\n",
    "    token_ids = [vocab.stoi[t] for t in tokens]\n",
    "    return {\"input_ids\": token_ids}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "eval_batch_size = 16\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=False)\n",
    "dev_dataset = dev_dataset.map(tokenize, batched=False)\n",
    "test_dataset = test_dataset.map(tokenize, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d752705a95b741028efb477be3475ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5049.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae8c083d5294f8b942ff584391676f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1683.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4536caceff92487d86d18346ec52bc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1677.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def format_dataset(dataset):\n",
    "    dataset = dataset.map(lambda examples: {'labels': examples['label']})\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'labels'])\n",
    "    return dataset\n",
    "\n",
    "train_dataset = format_dataset(train_dataset)\n",
    "dev_dataset = format_dataset(dev_dataset)\n",
    "test_dataset = format_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fasttext\n",
    "\n",
    "fasttext_model = fasttext.load_model(\"../../embeddings/cc.es.300.bin\")\n",
    "\n",
    "\n",
    "DIM = fasttext_model.get_word_vector(\"random\").shape[0]\n",
    "emb_matrix = torch.randn(len(vocab), DIM)\n",
    "UNK_IDX = vocab.stoi[\"<unk>\"]\n",
    "PAD_IDX = vocab.stoi[\"<pad>\"]\n",
    "\n",
    "# emb_matrix[UNK_IDX] = 0\n",
    "emb_matrix[PAD_IDX] = 0\n",
    "\n",
    "for i, word in enumerate(vocab.itos):\n",
    "    if i == UNK_IDX or i == PAD_IDX:\n",
    "        # Let them unmodified\n",
    "        pass\n",
    "    else:\n",
    "        emb_matrix[i] = torch.tensor(fasttext_model.get_word_vector(word))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "PAD_IDX = vocab.stoi[\"<pad>\"]\n",
    "\n",
    "def collate_batch(batch):\n",
    "    labels = [t[\"labels\"] for t in batch]\n",
    "    input_ids = [t[\"input_ids\"] for t in batch]\n",
    "\n",
    "    # Return text, text_lens, labels\n",
    "    return pad_sequence(input_ids, padding_value=PAD_IDX, batch_first=True), torch.tensor([len(t) for t in input_ids]), torch.tensor(labels)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_batch)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=16, collate_fn=collate_batch)\n",
    "test_dataset = DataLoader(test_dataset, batch_size=16, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from pysentimiento.emotion import id2label\n",
    "from pysentimiento.metrics import get_metrics\n",
    "from torch import nn\n",
    "\n",
    "class RNNModel(pl.LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dim, pad_idx, rnn_units, num_labels, num_layers=1,\n",
    "                 bidirectional=False, dropout=0.25, embedding_matrix=None, freeze_embeddings=True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                embedding_matrix, padding_idx=pad_idx,\n",
    "                freeze=freeze_embeddings\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(\n",
    "                vocab_size, embedding_dim,\n",
    "                padding_idx = pad_idx)\n",
    "\n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                   rnn_units,\n",
    "                   num_layers=num_layers,\n",
    "                   bidirectional=bidirectional, batch_first=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        factor = 2 if bidirectional else 1\n",
    "\n",
    "        self.fc = nn.Linear(rnn_units * factor, num_labels)\n",
    "\n",
    "    def forward(self, text, text_lens):\n",
    "        #text = [batch_size, text len]\n",
    "        #permuted = text.permute(1, 0)\n",
    "        # permuted shape [batch_size, sent len]\n",
    "        embedded = self.embedding(text)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
    "            # WTF no sé por qué hago esto de cpu\n",
    "            embedded, text_lens.to(\"cpu\"), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        packed_output, _ = self.rnn(packed_embedded)\n",
    "        # hidden is the last state of the\n",
    "\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        # output is shape [seq, batch, hid]\n",
    "        s = output.permute(1, 0, 2)\n",
    "        # now [batch, seq, hid]\n",
    "        mean = s.sum(dim=1) / text_lens.view(-1, 1)\n",
    "\n",
    "        return self.fc(mean)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, lens, y = batch\n",
    "        outs = self.forward(x, lens)\n",
    "        loss = F.cross_entropy(outs, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, lens, y = batch\n",
    "        outs = self.forward(x, lens)\n",
    "        loss = F.cross_entropy(outs, y)\n",
    "        preds = outs.argmax(-1).cpu()\n",
    "        metrics = get_metrics(preds, y.cpu(), id2label)\n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        for k, v in metrics.items():\n",
    "            self.log(\"val_\"+k, v, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, lens, y = batch\n",
    "        outs = self.forward(x, lens)\n",
    "        preds = outs.argmax(-1).cpu()\n",
    "        metrics = get_metrics(preds, y.cpu(), id2label)\n",
    "\n",
    "        for k, v in metrics.items():\n",
    "            self.log(\"test_\"+k, v, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | embedding | Embedding | 4.9 M \n",
      "1 | rnn       | GRU       | 428 K \n",
      "2 | dropout   | Dropout   | 0     \n",
      "3 | fc        | Linear    | 1.8 K \n",
      "----------------------------------------\n",
      "430 K     Trainable params\n",
      "4.9 M     Non-trainable params\n",
      "5.3 M     Total params\n",
      "21.297    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d7e7d19479412bab65ddd7f98bd118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bfc6c020b64514a40504e037f1a688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e79ad6e6634c50adee15bd800d4463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:610: LightningDeprecationWarning: Relying on `self.log('val_loss', ...)` to set the ModelCheckpoint monitor is deprecated in v1.2 and will be removed in v1.4. Please, create your own `mc = ModelCheckpoint(monitor='your_monitor')` and use it as `Trainer(callbacks=[mc])`.\n",
      "  warning_cache.deprecation(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674b958a289a40ba8cb377c78cfc9a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2b69807f724b7188117fd6ad150f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c732111da21477c8a5910af0aa085fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4295b839e06145b79284dd823cdcc9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2de3b62fe54a4ca496d1de5f4c1a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5f71c1a45247e7a837e678d6584cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a5192b467147568a31f2becec56f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2166784185454dae985e05c3a667a55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0536e9a6b94e958188128eae672ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = RNNModel(\n",
    "    vocab_size=len(vocab), embedding_dim=DIM, pad_idx=PAD_IDX, rnn_units=256, embedding_matrix=emb_matrix,\n",
    "    freeze_embeddings=True, num_labels=7,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10, \n",
    "    gpus=1\n",
    ")\n",
    "trainer.fit(model, train_dataloader, dev_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bee382dec4e48d981693642c7d9089b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.662492573261261,\n",
      " 'test_anger_f1': 0.15206381678581238,\n",
      " 'test_anger_precision': 0.18161116540431976,\n",
      " 'test_anger_recall': 0.15789207816123962,\n",
      " 'test_disgust_f1': 0.0,\n",
      " 'test_disgust_precision': 0.0,\n",
      " 'test_disgust_recall': 0.0,\n",
      " 'test_fear_f1': 0.03816338628530502,\n",
      " 'test_fear_precision': 0.043887894600629807,\n",
      " 'test_fear_recall': 0.03577817603945732,\n",
      " 'test_joy_f1': 0.4620981514453888,\n",
      " 'test_joy_precision': 0.46976178884506226,\n",
      " 'test_joy_recall': 0.48800334334373474,\n",
      " 'test_macro_f1': 0.21941280364990234,\n",
      " 'test_macro_precision': 0.22789530456066132,\n",
      " 'test_macro_recall': 0.23115865886211395,\n",
      " 'test_micro_f1': 0.662492573261261,\n",
      " 'test_others_f1': 0.6519678831100464,\n",
      " 'test_others_precision': 0.6186308264732361,\n",
      " 'test_others_recall': 0.7238366007804871,\n",
      " 'test_sadness_f1': 0.1889805644750595,\n",
      " 'test_sadness_precision': 0.21458955109119415,\n",
      " 'test_sadness_recall': 0.17888949811458588,\n",
      " 'test_surprise_f1': 0.04261578246951103,\n",
      " 'test_surprise_precision': 0.06678592413663864,\n",
      " 'test_surprise_recall': 0.033710990101099014}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_others_f1': 0.6519678831100464,\n",
       "  'test_others_precision': 0.6186308264732361,\n",
       "  'test_others_recall': 0.7238366007804871,\n",
       "  'test_joy_f1': 0.4620981514453888,\n",
       "  'test_joy_precision': 0.46976178884506226,\n",
       "  'test_joy_recall': 0.48800334334373474,\n",
       "  'test_sadness_f1': 0.1889805644750595,\n",
       "  'test_sadness_precision': 0.21458955109119415,\n",
       "  'test_sadness_recall': 0.17888949811458588,\n",
       "  'test_anger_f1': 0.15206381678581238,\n",
       "  'test_anger_precision': 0.18161116540431976,\n",
       "  'test_anger_recall': 0.15789207816123962,\n",
       "  'test_surprise_f1': 0.04261578246951103,\n",
       "  'test_surprise_precision': 0.06678592413663864,\n",
       "  'test_surprise_recall': 0.033710990101099014,\n",
       "  'test_disgust_f1': 0.0,\n",
       "  'test_disgust_precision': 0.0,\n",
       "  'test_disgust_recall': 0.0,\n",
       "  'test_fear_f1': 0.03816338628530502,\n",
       "  'test_fear_precision': 0.043887894600629807,\n",
       "  'test_fear_recall': 0.03577817603945732,\n",
       "  'test_micro_f1': 0.662492573261261,\n",
       "  'test_macro_f1': 0.21941280364990234,\n",
       "  'test_macro_precision': 0.22789530456066132,\n",
       "  'test_macro_recall': 0.23115865886211395,\n",
       "  'test_acc': 0.662492573261261}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fasttext\n",
    "\n",
    "fasttext_model = fasttext.load_model(\"../../embeddings/tweet_dim_300_ws_5.bin\")\n",
    "\n",
    "\n",
    "DIM = fasttext_model.get_word_vector(\"random\").shape[0]\n",
    "emb_matrix = torch.randn(len(vocab), DIM)\n",
    "UNK_IDX = vocab.stoi[\"<unk>\"]\n",
    "PAD_IDX = vocab.stoi[\"<pad>\"]\n",
    "\n",
    "# emb_matrix[UNK_IDX] = 0\n",
    "emb_matrix[PAD_IDX] = 0\n",
    "\n",
    "for i, word in enumerate(vocab.itos):\n",
    "    if i == UNK_IDX or i == PAD_IDX:\n",
    "        # Let them unmodified\n",
    "        pass\n",
    "    else:\n",
    "        emb_matrix[i] = torch.tensor(fasttext_model.get_word_vector(word))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | embedding | Embedding | 4.9 M \n",
      "1 | rnn       | GRU       | 428 K \n",
      "2 | dropout   | Dropout   | 0     \n",
      "3 | fc        | Linear    | 1.8 K \n",
      "----------------------------------------\n",
      "430 K     Trainable params\n",
      "4.9 M     Non-trainable params\n",
      "5.3 M     Total params\n",
      "21.297    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31774a21ce7144a1aa064d5a6f0d021f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94896d02002a4ecb8e6e03482ace4fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edfe73630a5440caaadc5b91e038100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384b366da0ec45bfb696f97f27f757c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919a5b46272a4ef78366de2d868ed769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1867f4a7fb0345ceb12ea5550c678882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf2385a80b84ec9909dda3f20386212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16646e047158430491897bbce79c3ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2022b69d5f6427697c30265da689c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be77dc053524801b11f029e28f18bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258c87e5c5544dbeab27b024b820718e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbd195b611b4763bcdf31d4522c6b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(\n",
    "    vocab_size=len(vocab), embedding_dim=DIM, pad_idx=PAD_IDX, rnn_units=256, embedding_matrix=emb_matrix,\n",
    "    freeze_embeddings=True, num_labels=7,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10, \n",
    "    gpus=1\n",
    ")\n",
    "trainer.fit(model, train_dataloader, dev_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cec8134af6841ad90e08005d11bd8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.6702444553375244,\n",
      " 'test_anger_f1': 0.13744033873081207,\n",
      " 'test_anger_precision': 0.16878779232501984,\n",
      " 'test_anger_recall': 0.12739886343479156,\n",
      " 'test_disgust_f1': 0.009540846571326256,\n",
      " 'test_disgust_precision': 0.009540846571326256,\n",
      " 'test_disgust_recall': 0.009540846571326256,\n",
      " 'test_fear_f1': 0.07155635207891464,\n",
      " 'test_fear_precision': 0.07473663240671158,\n",
      " 'test_fear_recall': 0.07632677257061005,\n",
      " 'test_joy_f1': 0.4897812604904175,\n",
      " 'test_joy_precision': 0.4881468415260315,\n",
      " 'test_joy_recall': 0.5282502174377441,\n",
      " 'test_macro_f1': 0.2342625856399536,\n",
      " 'test_macro_precision': 0.24061787128448486,\n",
      " 'test_macro_recall': 0.24590569734573364,\n",
      " 'test_micro_f1': 0.6702444553375244,\n",
      " 'test_others_f1': 0.650103747844696,\n",
      " 'test_others_precision': 0.6217681765556335,\n",
      " 'test_others_recall': 0.7159823179244995,\n",
      " 'test_sadness_f1': 0.21749188005924225,\n",
      " 'test_sadness_precision': 0.241837739944458,\n",
      " 'test_sadness_recall': 0.205959752202034,\n",
      " 'test_surprise_f1': 0.0639236718416214,\n",
      " 'test_surprise_precision': 0.07950706034898758,\n",
      " 'test_surprise_recall': 0.05788113549351692}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_others_f1': 0.650103747844696,\n",
       "  'test_others_precision': 0.6217681765556335,\n",
       "  'test_others_recall': 0.7159823179244995,\n",
       "  'test_joy_f1': 0.4897812604904175,\n",
       "  'test_joy_precision': 0.4881468415260315,\n",
       "  'test_joy_recall': 0.5282502174377441,\n",
       "  'test_sadness_f1': 0.21749188005924225,\n",
       "  'test_sadness_precision': 0.241837739944458,\n",
       "  'test_sadness_recall': 0.205959752202034,\n",
       "  'test_anger_f1': 0.13744033873081207,\n",
       "  'test_anger_precision': 0.16878779232501984,\n",
       "  'test_anger_recall': 0.12739886343479156,\n",
       "  'test_surprise_f1': 0.0639236718416214,\n",
       "  'test_surprise_precision': 0.07950706034898758,\n",
       "  'test_surprise_recall': 0.05788113549351692,\n",
       "  'test_disgust_f1': 0.009540846571326256,\n",
       "  'test_disgust_precision': 0.009540846571326256,\n",
       "  'test_disgust_recall': 0.009540846571326256,\n",
       "  'test_fear_f1': 0.07155635207891464,\n",
       "  'test_fear_precision': 0.07473663240671158,\n",
       "  'test_fear_recall': 0.07632677257061005,\n",
       "  'test_micro_f1': 0.6702444553375244,\n",
       "  'test_macro_f1': 0.2342625856399536,\n",
       "  'test_macro_precision': 0.24061787128448486,\n",
       "  'test_macro_recall': 0.24590569734573364,\n",
       "  'test_acc': 0.6702444553375244}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pysent-oyXQVI9B': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "1b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}