{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "In this notebook we show the results of our experiments for both tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\t\t\t    irony\n",
      "emotion_bert_base.json\t    sentiment\n",
      "emotion_bertweet_base.json  sentiment_bert_base.json\n",
      "emotion_beto.json\t    sentiment_bertweet_base.json\n",
      "emotion_distilbert_en.json  sentiment_beto.json\n",
      "emotion_distilbert_es.json  sentiment_distilbert_en.json\n",
      "emotion_mbert_en.json\t    sentiment_distilbert_es.json\n",
      "emotion_mbert_es.json\t    sentiment_mbert_en.json\n",
      "emotion_roberta.json\t    sentiment_mbert_es.json\n",
      "es\t\t\t    sentiment_roberta_base.json\n",
      "hate_speech\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!ls ../evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "../evaluations/sentiment_beto.json\n",
      "../evaluations/sentiment_roberta_base.json\n",
      "../evaluations/sentiment_mbert_en.json\n",
      "../evaluations/sentiment_bert_base.json\n",
      "../evaluations/sentiment_distilbert_es.json\n",
      "../evaluations/sentiment_bertweet_base.json\n",
      "../evaluations/sentiment_mbert_es.json\n",
      "../evaluations/sentiment_distilbert_en.json\n",
      "../evaluations/emotion_bertweet_base.json\n",
      "../evaluations/emotion_beto.json\n",
      "../evaluations/emotion_mbert_es.json\n",
      "../evaluations/emotion_mbert_en.json\n",
      "../evaluations/emotion_roberta.json\n",
      "../evaluations/emotion_bert_base.json\n",
      "../evaluations/emotion_distilbert_en.json\n",
      "../evaluations/emotion_distilbert_es.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import glob \n",
    "import json \n",
    "\n",
    "tasks = [\"sentiment\", \"emotion\"]\n",
    "\n",
    "files = [(task, f) for task in tasks for f in glob.glob(f\"../evaluations/{task}_*.json\")]\n",
    "\n",
    "evaluations = []\n",
    "\n",
    "for task, file in files:\n",
    "    print(file)\n",
    "    with open(file) as f:\n",
    "        evaluation = json.load(f)\n",
    "        evaluation[\"task\"] = task\n",
    "        evaluation[\"file\"] = file.split(\"/\")[-1]\n",
    "        evaluations.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for task in tasks:\n",
    "    df =  pd.DataFrame([\n",
    "        {**evaluation, **evaluation[\"metrics\"]} for evaluation in evaluations if evaluation[\"task\"] == task\n",
    "    ])\n",
    "\n",
    "    df.drop(labels=[\"predictions\", \"labels\", \"metrics\", \"file\"], inplace=True, axis=1)\n",
    "    df[\"model\"] = df[\"model\"].str.replace(\"models/\", \"\")\n",
    "\n",
    "    df[\"model\"] = df[\"model\"].str.replace(f\"-{task}-analysis/\", \"\")\n",
    "    df.columns = [col.replace(\"test_\", \"\").replace(\"_\", \" \").capitalize() for col in df.columns]\n",
    "    #df.set_index(\"Model\", inplace=True)\n",
    "    df = df.sort_values([\"Lang\", \"Macro f1\"]) \n",
    "    dfs[task] = df\n",
    "\n",
    "df = dfs[\"sentiment\"].merge(dfs[\"emotion\"], on=\"Model\", suffixes=(\"\", \"_emotion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Lang', 'Model', 'Task', 'Loss', 'Neg f1', 'Neg precision',\n",
       "       'Neg recall', 'Neu f1', 'Neu precision', 'Neu recall', 'Pos f1',\n",
       "       'Pos precision', 'Pos recall', 'Micro f1', 'Macro f1',\n",
       "       'Macro precision', 'Macro recall', 'Acc', 'Runtime',\n",
       "       'Samples per second', 'Lang_emotion', 'Task_emotion', 'Loss_emotion',\n",
       "       'Others f1', 'Others precision', 'Others recall', 'Joy f1',\n",
       "       'Joy precision', 'Joy recall', 'Sadness f1', 'Sadness precision',\n",
       "       'Sadness recall', 'Anger f1', 'Anger precision', 'Anger recall',\n",
       "       'Surprise f1', 'Surprise precision', 'Surprise recall', 'Disgust f1',\n",
       "       'Disgust precision', 'Disgust recall', 'Fear f1', 'Fear precision',\n",
       "       'Fear recall', 'Micro f1_emotion', 'Macro f1_emotion',\n",
       "       'Macro precision_emotion', 'Macro recall_emotion', 'Acc_emotion',\n",
       "       'Runtime_emotion', 'Samples per second_emotion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "        Model &         Lang &     Micro f1 &     Macro f1 &  Micro f1\\_emotion &  Macro f1\\_emotion \\\\\n",
      "\\midrule\n",
      "distilbert-en &           en &        0.649 &        0.642 &             0.503 &             0.383 \\\\\n",
      "     mbert-en &           en &        0.645 &        0.643 &             0.516 &             0.394 \\\\\n",
      " roberta-base &           en &        0.686 &        0.684 &             0.563 &             0.445 \\\\\n",
      "    bert-base &           en &        0.686 &        0.684 &             0.559 &             0.439 \\\\\n",
      "bertweet-base &           en &        0.697 &        0.696 &             0.584 &             0.476 \\\\\n",
      "distilbert-es &           es &        0.602 &        0.599 &             0.600 &             0.463 \\\\\n",
      "     mbert-es &           es &        0.609 &        0.604 &             0.610 &             0.474 \\\\\n",
      "         beto &           es &        0.672 &        0.667 &             0.688 &             0.548 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_columns = [\"Model\", \"Lang\"]\n",
    "\n",
    "df.sort_values([\"Lang\", \"Macro f1\"], inplace=True) \n",
    "sentiment_columns = [\n",
    "    #\"Pos f1\", \n",
    "    #\"Neu f1\", \n",
    "    #\"Neg f1\", \n",
    "    \"Micro f1\",\n",
    "    \"Macro f1\"\n",
    "]\n",
    "emotion_columns = [\n",
    "    #\"Joy f1\",\n",
    "    #\"Others f1\",\n",
    "    #\"Sadness f1\",\n",
    "    #\"Anger f1\",\n",
    "    #\"Disgust f1\",\n",
    "    \"Micro f1_emotion\",\n",
    "    \"Macro f1_emotion\"\n",
    "]\n",
    "\n",
    "print(df[base_columns + sentiment_columns + emotion_columns].to_latex(index=False, float_format=\"{0:.3f}\".format, col_space=12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model         | Lang   |   Others f1 |   Joy f1 |   Sadness f1 |   Anger f1 |   Surprise f1 |   Disgust f1 |   Fear f1 |   Macro f1 |\n",
      "|:--------------|:-------|------------:|---------:|-------------:|-----------:|--------------:|-------------:|----------:|-----------:|\n",
      "| distilbert-en | en     |    0.509407 | 0.665484 |     0.502165 |   0.30303  |      0.147541 |     0.351111 |  0.201835 |   0.382939 |\n",
      "| mbert-en      | en     |    0.547718 | 0.650691 |     0.544643 |   0.29703  |      0.102941 |     0.356989 |  0.255319 |   0.393619 |\n",
      "| bert-base     | en     |    0.59398  | 0.683521 |     0.541485 |   0.355769 |      0.238411 |     0.408867 |  0.252632 |   0.439238 |\n",
      "| roberta-base  | en     |    0.573888 | 0.689527 |     0.547945 |   0.363636 |      0.212389 |     0.472656 |  0.255814 |   0.445122 |\n",
      "| bertweet-base | en     |    0.606019 | 0.711069 |     0.608696 |   0.433862 |      0.257669 |     0.452489 |  0.26     |   0.475686 |\n",
      "| distilbert-es | es     |    0.678962 | 0.60223  |     0.716707 |   0.434316 |      0.264368 |     0.084507 |  0.461538 |   0.463233 |\n",
      "| mbert-es      | es     |    0.691127 | 0.585242 |     0.710462 |   0.490566 |      0.273292 |     0.133333 |  0.431373 |   0.473628 |\n",
      "| beto          | es     |    0.74937  | 0.671916 |     0.753695 |   0.573684 |      0.396694 |     0.153846 |  0.533333 |   0.547506 |\n"
     ]
    }
   ],
   "source": [
    "f1_columns = [col for col in df.columns if \"f1\" in col and \"Macro\" not in col]\n",
    "print(df[[\"Model\", \"Lang\"] + f1_columns + [\"Macro f1\"]].to_markdown(index=False))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "387abc9bc94d8eb1bd0148a5d4cb2bf99bc3b40fa501b808e2b508b4f65ed831"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pysent-oyXQVI9B': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "1b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
