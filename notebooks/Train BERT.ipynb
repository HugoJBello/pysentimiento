{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4802 2443 7264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pandas/core/computation/expressions.py:68: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return op(a, b)\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pandas/core/computation/expressions.py:68: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return op(a, b)\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pandas/core/computation/expressions.py:68: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return op(a, b)\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pandas/core/computation/expressions.py:68: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return op(a, b)\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pandas/core/computation/expressions.py:68: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return op(a, b)\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pandas/core/computation/expressions.py:68: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return op(a, b)\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pandas/core/computation/expressions.py:68: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return op(a, b)\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pandas/core/computation/expressions.py:68: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return op(a, b)\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pandas/core/computation/expressions.py:68: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return op(a, b)\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pandas/core/computation/expressions.py:68: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Index(['text', 'polarity', 'label'], dtype='object'),\n",
       " Index(['text', 'polarity', 'label'], dtype='object'),\n",
       " Index(['text', 'polarity', 'label'], dtype='object'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "def get_lang(file):\n",
    "    return os.path.splitext(os.path.basename(file))[0]\n",
    "\n",
    "def load_df(file):\n",
    "    dialect = get_lang(file)\n",
    "    \n",
    "    df = pd.read_table(file, names=[\"id\", \"text\", \"polarity\"], index_col=0)\n",
    "    #df[\"dialect\"] = dialect\n",
    "    df[\"label\"] = 1\n",
    "    df.loc[df[\"polarity\"] == 'P', \"label\"] = 2\n",
    "    df.loc[df[\"polarity\"] == 'N', \"label\"] = 0\n",
    "    return df\n",
    "\n",
    "train_files = glob(\"../data/tass2020/train/*.tsv\")\n",
    "dev_files = glob(\"../data/tass2020/dev/*.tsv\")\n",
    "test_files = glob(\"../data/tass2020/test1.1/*.tsv\")\n",
    "\n",
    "train_dfs = {get_lang(file):load_df(file) for file in train_files}\n",
    "dev_dfs = {get_lang(file):load_df(file) for file in dev_files}\n",
    "test_dfs = {get_lang(file):load_df(file) for file in test_files}\n",
    "\n",
    "train_df = pd.concat(train_dfs.values())\n",
    "dev_df = pd.concat(dev_dfs.values())\n",
    "test_df = pd.concat(test_dfs.values())\n",
    "\n",
    "print(len(train_df), len(dev_df), len(test_df))\n",
    "\n",
    "train_df.columns, dev_df.columns, test_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Convertimos todos los usuarios al string \"usuario\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'usuario usuario jajaja me muero'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile(r\"@[a-zA-Z0-9_]{0,15}\")\n",
    "\n",
    "\n",
    "regex.sub(\"usuario\", \"@infobae @OnlyInPeronia jajaja me muero\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_regex = re.compile(r\"@[a-zA-Z0-9_]{0,15}\")\n",
    "url_regex = re.compile(\n",
    "    \"((?<=[^a-zA-Z0-9])(?:https?\\:\\/\\/|[a-zA-Z0-9]{1,}\\.{1}|\\b)(?:\\w{1,}\\.{1}){1,5}(?:com|co|org|edu|gov|uk|net|ca|de|jp|fr|au|us|ru|ch|it|nl|se|no|es|mil|iq|io|ac|ly|sm){1}(?:\\/[a-zA-Z0-9]{1,})*)\"\n",
    ")\n",
    "def preprocess_tweet(text):\n",
    "    \"\"\"\n",
    "    Basic preprocessing\n",
    "    \"\"\"\n",
    "    text = user_regex.sub(\"usuario\", text)\n",
    "    text = url_regex.sub(\"url\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "train_df[\"text\"] = train_df[\"text\"].apply(preprocess_tweet)\n",
    "dev_df[\"text\"] = dev_df[\"text\"].apply(preprocess_tweet)\n",
    "test_df[\"text\"] = test_df[\"text\"].apply(preprocess_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "model_name = 'dccuchile/bert-base-spanish-wwm-cased'\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=3)\n",
    "\n",
    "model.config.hidden_dropout_prob = 0.20\n",
    "model = model.to(device)\n",
    "model.train();\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "tokenizer.model_max_length = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos primero las longitudes (a ver si no hay nada mal cargado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch version 1.4.0 available.\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Value, ClassLabel, Features\n",
    "\n",
    "examples = pd.concat([train_df, dev_df])\n",
    "\n",
    "features = Features({\n",
    "    'text': Value('string'),\n",
    "    'label': ClassLabel(num_classes=3, names=[\"neg\", \"neu\", \"pos\"])\n",
    "})\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"text\", \"label\"]], features=features)\n",
    "dev_dataset = Dataset.from_pandas(dev_df[[\"text\", \"label\"]], features=features)\n",
    "test_dataset = Dataset.from_pandas(test_df[[\"text\", \"label\"]], features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(num_classes=3, names=['neg', 'neu', 'pos'], names_file=None, id=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing the mapped function outputs\n",
      "Testing finished, running the mapping function on the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdab6e2795642069a0920691c96e074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=151.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 4802 examples in 15287950 bytes .\n",
      "Testing the mapped function outputs\n",
      "Testing finished, running the mapping function on the dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f3cd38fcb348e4857b87f5a270f81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=153.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 2443 examples in 7788684 bytes .\n",
      "Testing the mapped function outputs\n",
      "Testing finished, running the mapping function on the dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5526c237dbe498da47248c278450125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=454.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 7264 examples in 23088522 bytes .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "eval_batch_size = 16\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=batch_size)\n",
    "dev_dataset = dev_dataset.map(tokenize, batched=True, batch_size=eval_batch_size)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=eval_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing the mapped function outputs\n",
      "Testing finished, running the mapping function on the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bdb330a77549ed9d85eaaf099bf17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4802.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 4802 examples in 15324030 bytes .\n",
      "Set __getitem__(key) output type to torch for ['input_ids', 'token_type_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Testing the mapped function outputs\n",
      "Testing finished, running the mapping function on the dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c5329c4b9d408bad684c0efd4f3edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2443.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 2443 examples in 7805828 bytes .\n",
      "Set __getitem__(key) output type to torch for ['input_ids', 'token_type_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Testing the mapped function outputs\n",
      "Testing finished, running the mapping function on the dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd3dbf1234142af915ed75de4ef27d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7264.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 7264 examples in 23139498 bytes .\n",
      "Set __getitem__(key) output type to torch for ['input_ids', 'token_type_ids', 'attention_mask', 'labels'] columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def format_dataset(dataset):\n",
    "    dataset = dataset.map(lambda examples: {'labels': examples['label']})\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "    return dataset\n",
    "\n",
    "train_dataset = format_dataset(train_dataset)\n",
    "dev_dataset = format_dataset(dev_dataset)\n",
    "test_dataset = format_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext import data\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_it = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "dev_it = torch.utils.data.DataLoader(dev_dataset, batch_size=batch_size)\n",
    "test_it = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def compute_metrics(labels, preds):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate(model, it):\n",
    "    \"\"\"\n",
    "    Calculates labels and predictions for it\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    (labels, preds): torch.Tensor\n",
    "    \n",
    "    where labels are the true labels\n",
    "    and preds are the predictions\n",
    "    \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    true = []\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(it)):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs[0]\n",
    "            losses.append(loss.item())\n",
    "            outs = torch.softmax(outputs.logits, dim=1)\n",
    "            \n",
    "            true.append(batch['labels'].cpu())\n",
    "            preds.append(outs.cpu())\n",
    "    return np.array(losses).mean(), torch.cat(true), torch.cat(preds).argmax(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298487d0901f409fb9f397cda2892303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=151.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a0e54cf2f042a48bd7fb8a409a4884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 \n",
      "Train loss 1.0225\n",
      "Dev loss 0.8845\n",
      "Dev metrics {'accuracy': 0.5800245599672533, 'f1': 0.5273043035005734, 'precision': 0.6051953379716025, 'recall': 0.5576677030266969}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058b418af542471f86484ee502a44d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=151.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985a6b1a44f5410ea12e383c8502674e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 \n",
      "Train loss 0.7186\n",
      "Dev loss 0.7838\n",
      "Dev metrics {'accuracy': 0.6557511256651658, 'f1': 0.6487443410843955, 'precision': 0.6512699498404012, 'recall': 0.6498570983064563}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee6344cb97e452d913f2933201033c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=151.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e49a0200efe40f1a6e63392a731de8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 \n",
      "Train loss 0.4615\n",
      "Dev loss 0.8428\n",
      "Dev metrics {'accuracy': 0.6672124437167417, 'f1': 0.666598901550708, 'precision': 0.6666833824123274, 'recall': 0.6668643310869594}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f9847e5e3244a79023b9f0879c8a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=151.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a16384a0a84179a32f5ea111e370e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 \n",
      "Train loss 0.2727\n",
      "Dev loss 0.9440\n",
      "Dev metrics {'accuracy': 0.6598444535407286, 'f1': 0.6599412534946892, 'precision': 0.6627497177983619, 'recall': 0.6581376777968915}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc5c04b4c1d49b396b2f17fba95adb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=151.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275a05fbdbc84811963680accb92616f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 \n",
      "Train loss 0.1623\n",
      "Dev loss 1.1059\n",
      "Dev metrics {'accuracy': 0.6557511256651658, 'f1': 0.6474144558141375, 'precision': 0.654672224443276, 'recall': 0.6465583383009803}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bfe7b26a1d4af6a48c94d3ac6cfab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=151.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79a536e617e4375805b406023e9acde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 \n",
      "Train loss 0.0993\n",
      "Dev loss 1.2006\n",
      "Dev metrics {'accuracy': 0.6635284486287352, 'f1': 0.6558691210795763, 'precision': 0.6538927217178321, 'recall': 0.6620069116834751}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11161746a31b4830b5a2feacf71b297b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=151.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3f687a44694415ab892cd64501410d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 \n",
      "Train loss 0.0756\n",
      "Dev loss 1.2851\n",
      "Dev metrics {'accuracy': 0.6565697912402784, 'f1': 0.6506782375001033, 'precision': 0.6505409574102564, 'recall': 0.6613688474139242}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5c1a15472648a08ad5edc51c10ec66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=151.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa171ed4e674e00a09ed53042d157ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 \n",
      "Train loss 0.0538\n",
      "Dev loss 1.2985\n",
      "Dev metrics {'accuracy': 0.6573884568153909, 'f1': 0.6609376840923649, 'precision': 0.6754349423222621, 'recall': 0.6560415107195824}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65dd5a34fab14923927f760443dcdbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=151.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865d1bf916374e7abc2fca7f5ab69115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 \n",
      "Train loss 0.0326\n",
      "Dev loss 1.4343\n",
      "Dev metrics {'accuracy': 0.6299631600491199, 'f1': 0.6387203807640974, 'precision': 0.6770675321978743, 'recall': 0.6374226806409898}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b612feb7c82f426282eeaa4f47e5041e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=151.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6f542c31c64b68a654745350308649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 \n",
      "Train loss 0.0272\n",
      "Dev loss 1.3530\n",
      "Dev metrics {'accuracy': 0.6643471142038477, 'f1': 0.6649911260793954, 'precision': 0.6719269024188338, 'recall': 0.6612119098544086}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.train().to(device)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "num_training_steps = epochs * len(train_it)\n",
    "num_warmup_steps = num_training_steps // 10\n",
    "warmup_proportion = float(num_warmup_steps) / float(num_training_steps)  # 0.1\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    for i, batch in enumerate(tqdm(train_it)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs[0]\n",
    "        train_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    train_loss = np.array(train_losses).mean()\n",
    "    dev_loss, dev_labels, dev_preds = evaluate(model, dev_it)\n",
    "    dev_metrics = compute_metrics(dev_labels, dev_preds) \n",
    "    \n",
    "    print(f\"Epoch {epoch:<2}\")\n",
    "    print(f\"Train loss {train_loss:.4f}\")\n",
    "    print(f\"Dev loss {dev_loss:.4f}\")\n",
    "    print(f\"Dev metrics {dev_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/beto-sentiment-analysis/vocab.txt',\n",
       " '../models/beto-sentiment-analysis/special_tokens_map.json',\n",
       " '../models/beto-sentiment-analysis/added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../models/beto-sentiment-analysis\"\n",
    "model.save_pretrained(path)\n",
    "tokenizer.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
