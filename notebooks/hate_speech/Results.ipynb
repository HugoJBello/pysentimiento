{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10 beto evaluations\n",
      "We have 10 beto-hier evaluations\n",
      "We have 10 robertuito evaluations\n",
      "We have 10 robertuito-hier evaluations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beto mean</th>\n",
       "      <th>beto std</th>\n",
       "      <th>beto-hier mean</th>\n",
       "      <th>beto-hier std</th>\n",
       "      <th>robertuito mean</th>\n",
       "      <th>robertuito std</th>\n",
       "      <th>robertuito-hier mean</th>\n",
       "      <th>robertuito-hier std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hs_f1</th>\n",
       "      <td>0.740521</td>\n",
       "      <td>0.010502</td>\n",
       "      <td>0.740255</td>\n",
       "      <td>0.008907</td>\n",
       "      <td>0.776505</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>0.780669</td>\n",
       "      <td>0.003177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_precision</th>\n",
       "      <td>0.674813</td>\n",
       "      <td>0.021768</td>\n",
       "      <td>0.700396</td>\n",
       "      <td>0.037505</td>\n",
       "      <td>0.696542</td>\n",
       "      <td>0.019935</td>\n",
       "      <td>0.733565</td>\n",
       "      <td>0.030827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_recall</th>\n",
       "      <td>0.821818</td>\n",
       "      <td>0.027068</td>\n",
       "      <td>0.789848</td>\n",
       "      <td>0.049778</td>\n",
       "      <td>0.878485</td>\n",
       "      <td>0.022987</td>\n",
       "      <td>0.837576</td>\n",
       "      <td>0.041530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr_f1</th>\n",
       "      <td>0.758743</td>\n",
       "      <td>0.013401</td>\n",
       "      <td>0.758010</td>\n",
       "      <td>0.007796</td>\n",
       "      <td>0.808900</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.812730</td>\n",
       "      <td>0.007353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ag_f1</th>\n",
       "      <td>0.681657</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>0.672036</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>0.703604</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.018617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_hs_f1_score</th>\n",
       "      <td>0.760522</td>\n",
       "      <td>0.012299</td>\n",
       "      <td>0.767605</td>\n",
       "      <td>0.013241</td>\n",
       "      <td>0.790274</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>0.803078</td>\n",
       "      <td>0.006420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emr_no_gating</th>\n",
       "      <td>0.660562</td>\n",
       "      <td>0.016657</td>\n",
       "      <td>0.366625</td>\n",
       "      <td>0.100681</td>\n",
       "      <td>0.676875</td>\n",
       "      <td>0.013652</td>\n",
       "      <td>0.404563</td>\n",
       "      <td>0.043760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emr</th>\n",
       "      <td>0.661500</td>\n",
       "      <td>0.017130</td>\n",
       "      <td>0.681437</td>\n",
       "      <td>0.023805</td>\n",
       "      <td>0.677625</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.707937</td>\n",
       "      <td>0.018234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_f1</th>\n",
       "      <td>0.726974</td>\n",
       "      <td>0.009220</td>\n",
       "      <td>0.723434</td>\n",
       "      <td>0.010407</td>\n",
       "      <td>0.763003</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.007684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   beto mean  beto std  beto-hier mean  beto-hier std  \\\n",
       "hs_f1               0.740521  0.010502        0.740255       0.008907   \n",
       "hs_precision        0.674813  0.021768        0.700396       0.037505   \n",
       "hs_recall           0.821818  0.027068        0.789848       0.049778   \n",
       "tr_f1               0.758743  0.013401        0.758010       0.007796   \n",
       "ag_f1               0.681657  0.012650        0.672036       0.020582   \n",
       "macro_hs_f1_score   0.760522  0.012299        0.767605       0.013241   \n",
       "emr_no_gating       0.660562  0.016657        0.366625       0.100681   \n",
       "emr                 0.661500  0.017130        0.681437       0.023805   \n",
       "macro_f1            0.726974  0.009220        0.723434       0.010407   \n",
       "\n",
       "                   robertuito mean  robertuito std  robertuito-hier mean  \\\n",
       "hs_f1                     0.776505        0.004770              0.780669   \n",
       "hs_precision              0.696542        0.019935              0.733565   \n",
       "hs_recall                 0.878485        0.022987              0.837576   \n",
       "tr_f1                     0.808900        0.005051              0.812730   \n",
       "ag_f1                     0.703604        0.005369              0.702251   \n",
       "macro_hs_f1_score         0.790274        0.008576              0.803078   \n",
       "emr_no_gating             0.676875        0.013652              0.404563   \n",
       "emr                       0.677625        0.013571              0.707937   \n",
       "macro_f1                  0.763003        0.004019              0.765217   \n",
       "\n",
       "                   robertuito-hier std  \n",
       "hs_f1                         0.003177  \n",
       "hs_precision                  0.030827  \n",
       "hs_recall                     0.041530  \n",
       "tr_f1                         0.007353  \n",
       "ag_f1                         0.018617  \n",
       "macro_hs_f1_score             0.006420  \n",
       "emr_no_gating                 0.043760  \n",
       "emr                           0.018234  \n",
       "macro_f1                      0.007684  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "evaluations = {\n",
    "\n",
    "}\n",
    "\n",
    "for model_name, path in [\n",
    "    ('beto', '../../evaluations/hate_speech/beto-taskb.json'),\n",
    "    ('beto-hier', '../../evaluations/hate_speech/beto-taskb-hier.json'),\n",
    "    ('robertuito', '../../evaluations/hate_speech/robertuito-taskb.json'),\n",
    "    ('robertuito-hier', '../../evaluations/hate_speech/robertuito-taskb-hier.json'),\n",
    "    #('robertuito-deacc', '../../evaluations/robertuito-deacc-hate-speech-task-b.json'),\n",
    "    ]:\n",
    "    with open(path) as f:\n",
    "        evaluations[model_name] = json.load(f)\n",
    "\n",
    "\n",
    "for key, evals in evaluations.items():\n",
    "    print(f\"We have {len(evals['evaluations']['hate_speech'])} {key} evaluations\")\n",
    "\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for model_name, model_results in evaluations.items():\n",
    "    model_evaluations = model_results[\"evaluations\"][\"hate_speech\"]\n",
    "    \n",
    "    if not model_evaluations:\n",
    "        continue\n",
    "    \n",
    "    df = pd.DataFrame(model_evaluations)\n",
    "\n",
    "    df.columns = [x.split(\"_\", 1)[1] if \"_\" in x else x for x in df.columns]\n",
    "    \n",
    "    mean_df = pd.DataFrame({\n",
    "        f\"{model_name} mean\": df.mean(), \n",
    "        f\"{model_name} std\": df.std()\n",
    "    })\n",
    "    dfs.append(mean_df)\n",
    "\n",
    "result_df = pd.concat(dfs, axis=1)\n",
    "index = [\n",
    "    'hs_f1', 'hs_precision', 'hs_recall', 'tr_f1',\n",
    "    'ag_f1', 'macro_hs_f1_score',\n",
    "    'emr_no_gating', 'emr', \n",
    "    'macro_f1',\n",
    "]\n",
    "result_df.loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../../evaluations/hate_speech/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "387abc9bc94d8eb1bd0148a5d4cb2bf99bc3b40fa501b808e2b508b4f65ed831"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('pysentimiento-bwlKzHxB-py3.7': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
