{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beto-hierarchical-gamma-0.1.json  beto.json\n"
     ]
    }
   ],
   "source": [
    "!ls ../../evaluations/hate_speech/task_b/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'dccuchile/bert-base-spanish-wwm-uncased',\n",
       " 'lang': 'es',\n",
       " 'train_args': {'epochs': 5,\n",
       "  'batch_size': 32,\n",
       "  'eval_batch_size': 16,\n",
       "  'warmup_ratio': 0.1,\n",
       "  'limit': None,\n",
       "  'task_b': True,\n",
       "  'metric_for_best_model': 'emr',\n",
       "  'hierarchical': True,\n",
       "  'gamma': 0.005},\n",
       " 'evaluations': {'hate_speech': [{'eval_loss': 22.860462188720703,\n",
       "    'eval_hs_f1': 0.7242105263157895,\n",
       "    'eval_hs_precision': 0.6745098039215687,\n",
       "    'eval_hs_recall': 0.7818181818181819,\n",
       "    'eval_tr_f1': 0.7445255474452555,\n",
       "    'eval_tr_precision': 0.7669172932330827,\n",
       "    'eval_tr_recall': 0.723404255319149,\n",
       "    'eval_ag_f1': 0.6778711484593837,\n",
       "    'eval_ag_precision': 0.6080402010050251,\n",
       "    'eval_ag_recall': 0.7658227848101266,\n",
       "    'eval_macro_hs_f1_score': 0.7514010378057822,\n",
       "    'eval_emr_no_gating': 0.6275,\n",
       "    'eval_emr': 0.66625,\n",
       "    'eval_macro_f1': 0.7155357003211975,\n",
       "    'eval_macro_precision': 0.6831557750701904,\n",
       "    'eval_macro_recall': 0.75701504945755,\n",
       "    'eval_runtime': 3.1087,\n",
       "    'eval_samples_per_second': 514.689,\n",
       "    'eval_steps_per_second': 32.168,\n",
       "    'epoch': 5.0},\n",
       "   {'eval_loss': 23.43826675415039,\n",
       "    'eval_hs_f1': 0.7327707454289732,\n",
       "    'eval_hs_precision': 0.6837270341207349,\n",
       "    'eval_hs_recall': 0.7893939393939394,\n",
       "    'eval_tr_f1': 0.7475961538461539,\n",
       "    'eval_tr_precision': 0.7603911980440098,\n",
       "    'eval_tr_recall': 0.735224586288416,\n",
       "    'eval_ag_f1': 0.689908256880734,\n",
       "    'eval_ag_precision': 0.6103896103896104,\n",
       "    'eval_ag_recall': 0.7932489451476793,\n",
       "    'eval_macro_hs_f1_score': 0.7595237304197735,\n",
       "    'eval_emr_no_gating': 0.628125,\n",
       "    'eval_emr': 0.67375,\n",
       "    'eval_macro_f1': 0.7234250903129578,\n",
       "    'eval_macro_precision': 0.6848359107971191,\n",
       "    'eval_macro_recall': 0.7726225256919861,\n",
       "    'eval_runtime': 3.3495,\n",
       "    'eval_samples_per_second': 477.683,\n",
       "    'eval_steps_per_second': 29.855,\n",
       "    'epoch': 5.0},\n",
       "   {'eval_loss': 16.16846466064453,\n",
       "    'eval_hs_f1': 0.7412480974124811,\n",
       "    'eval_hs_precision': 0.7446483180428135,\n",
       "    'eval_hs_recall': 0.7378787878787879,\n",
       "    'eval_tr_f1': 0.7433414043583535,\n",
       "    'eval_tr_precision': 0.7617866004962779,\n",
       "    'eval_tr_recall': 0.7257683215130024,\n",
       "    'eval_ag_f1': 0.6875,\n",
       "    'eval_ag_precision': 0.6237113402061856,\n",
       "    'eval_ag_recall': 0.7658227848101266,\n",
       "    'eval_macro_hs_f1_score': 0.7804861908059224,\n",
       "    'eval_emr_no_gating': 0.5475,\n",
       "    'eval_emr': 0.7075,\n",
       "    'eval_macro_f1': 0.7240298390388489,\n",
       "    'eval_macro_precision': 0.7100487351417542,\n",
       "    'eval_macro_recall': 0.7431566119194031,\n",
       "    'eval_runtime': 3.3179,\n",
       "    'eval_samples_per_second': 482.231,\n",
       "    'eval_steps_per_second': 30.139,\n",
       "    'epoch': 5.0},\n",
       "   {'eval_loss': 16.32044219970703,\n",
       "    'eval_hs_f1': 0.7531034482758621,\n",
       "    'eval_hs_precision': 0.6911392405063291,\n",
       "    'eval_hs_recall': 0.8272727272727273,\n",
       "    'eval_tr_f1': 0.7667057444314185,\n",
       "    'eval_tr_precision': 0.7604651162790698,\n",
       "    'eval_tr_recall': 0.7730496453900709,\n",
       "    'eval_ag_f1': 0.6738589211618258,\n",
       "    'eval_ag_precision': 0.5554035567715458,\n",
       "    'eval_ag_recall': 0.8565400843881856,\n",
       "    'eval_macro_hs_f1_score': 0.7742660098522167,\n",
       "    'eval_emr_no_gating': 0.485625,\n",
       "    'eval_emr': 0.6775,\n",
       "    'eval_macro_f1': 0.7312226891517639,\n",
       "    'eval_macro_precision': 0.6690025925636292,\n",
       "    'eval_macro_recall': 0.8189541697502136,\n",
       "    'eval_runtime': 3.2105,\n",
       "    'eval_samples_per_second': 498.366,\n",
       "    'eval_steps_per_second': 31.148,\n",
       "    'epoch': 5.0}]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations[\"beto-hier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10 beto evaluations\n",
      "We have 10 beto-hier evaluations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beto mean</th>\n",
       "      <th>beto std</th>\n",
       "      <th>beto-hier mean</th>\n",
       "      <th>beto-hier std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hs_f1</th>\n",
       "      <td>0.741171</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>0.734925</td>\n",
       "      <td>0.013436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_precision</th>\n",
       "      <td>0.712582</td>\n",
       "      <td>0.041683</td>\n",
       "      <td>0.743658</td>\n",
       "      <td>0.020801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_recall</th>\n",
       "      <td>0.777879</td>\n",
       "      <td>0.054317</td>\n",
       "      <td>0.727576</td>\n",
       "      <td>0.030116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr_f1</th>\n",
       "      <td>0.765226</td>\n",
       "      <td>0.012095</td>\n",
       "      <td>0.758053</td>\n",
       "      <td>0.014196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ag_f1</th>\n",
       "      <td>0.687683</td>\n",
       "      <td>0.014856</td>\n",
       "      <td>0.674417</td>\n",
       "      <td>0.013812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_hs_f1_score</th>\n",
       "      <td>0.771392</td>\n",
       "      <td>0.014996</td>\n",
       "      <td>0.776030</td>\n",
       "      <td>0.010041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emr_no_gating</th>\n",
       "      <td>0.684063</td>\n",
       "      <td>0.025306</td>\n",
       "      <td>0.673875</td>\n",
       "      <td>0.016543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emr</th>\n",
       "      <td>0.684812</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.703313</td>\n",
       "      <td>0.011592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_f1</th>\n",
       "      <td>0.731360</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>0.722465</td>\n",
       "      <td>0.009771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   beto mean  beto std  beto-hier mean  beto-hier std\n",
       "hs_f1               0.741171  0.013294        0.734925       0.013436\n",
       "hs_precision        0.712582  0.041683        0.743658       0.020801\n",
       "hs_recall           0.777879  0.054317        0.727576       0.030116\n",
       "tr_f1               0.765226  0.012095        0.758053       0.014196\n",
       "ag_f1               0.687683  0.014856        0.674417       0.013812\n",
       "macro_hs_f1_score   0.771392  0.014996        0.776030       0.010041\n",
       "emr_no_gating       0.684063  0.025306        0.673875       0.016543\n",
       "emr                 0.684812  0.025478        0.703313       0.011592\n",
       "macro_f1            0.731360  0.011938        0.722465       0.009771"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "evaluations = {\n",
    "\n",
    "}\n",
    "\n",
    "for model_name, path in [\n",
    "    ('beto', '../../evaluations/hate_speech/task_b/beto.json'),\n",
    "    ('beto-hier', '../../evaluations/hate_speech/task_b/beto-hierarchical-gamma-0.1.json'),\n",
    "    #('robertuito', '../../evaluations/hate_speech/robertuito-taskb.json'),\n",
    "    #('robertuito-hier', '../../evaluations/hate_speech/robertuito-taskb-hier.json'),\n",
    "    #('robertuito-deacc', '../../evaluations/robertuito-deacc-hate-speech-task-b.json'),\n",
    "    ]:\n",
    "    with open(path) as f:\n",
    "        evaluations[model_name] = json.load(f)\n",
    "\n",
    "\n",
    "for key, evals in evaluations.items():\n",
    "    print(f\"We have {len(evals['evaluations']['hate_speech'])} {key} evaluations\")\n",
    "\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for model_name, model_results in evaluations.items():\n",
    "    model_evaluations = model_results[\"evaluations\"][\"hate_speech\"]\n",
    "    \n",
    "    if not model_evaluations:\n",
    "        continue\n",
    "    \n",
    "    df = pd.DataFrame(model_evaluations)\n",
    "\n",
    "    df.columns = [x.split(\"_\", 1)[1] if \"_\" in x else x for x in df.columns]\n",
    "    \n",
    "    mean_df = pd.DataFrame({\n",
    "        f\"{model_name} mean\": df.mean(), \n",
    "        f\"{model_name} std\": df.std()\n",
    "    })\n",
    "    dfs.append(mean_df)\n",
    "\n",
    "result_df = pd.concat(dfs, axis=1)\n",
    "index = [\n",
    "    'hs_f1', 'hs_precision', 'hs_recall', 'tr_f1',\n",
    "    'ag_f1', 'macro_hs_f1_score',\n",
    "    'emr_no_gating', 'emr', \n",
    "    'macro_f1',\n",
    "]\n",
    "result_df.loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=73.5, pvalue=0.04093431186532218)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "beto_hier_emrs = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"beto-hier\"][\"evaluations\"][\"hate_speech\"]]\n",
    "beto_emrs = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"beto\"][\"evaluations\"][\"hate_speech\"]]\n",
    "\n",
    "scipy.stats.mannwhitneyu(beto_hier_emrs, beto_emrs, alternative=\"greater\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "387abc9bc94d8eb1bd0148a5d4cb2bf99bc3b40fa501b808e2b508b4f65ed831"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('pysentimiento-bwlKzHxB-py3.7': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
