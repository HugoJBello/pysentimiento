{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning BETO\n",
    "\n",
    "In this notebook, we will check what happens if we fine tune using MLM on the TASS tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForMaskedLM, BertTokenizerFast\n",
    "\n",
    "model_name = 'dccuchile/bert-base-spanish-wwm-cased'\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained(model_name, return_dict=True, num_labels=3)\n",
    "model = model.to(device)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "tokenizer.model_max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "tweet_files = glob(\"../data/tweets/spanish/*.txt\")\n",
    "\n",
    "tweet_files = tweet_files[:100]\n",
    "limit = int(0.93 * len(tweet_files))\n",
    "train_files = tweet_files[:limit]\n",
    "dev_files = tweet_files[limit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/default-6cc9eaa74e5a23f7 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/jmperez/.cache/huggingface/datasets/text/default-6cc9eaa74e5a23f7/0.0.0/52cefbb2b82b015d4253f1aeb1e6ee5591124a6491e834acfe1751f765925155...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /home/jmperez/.cache/huggingface/datasets/text/default-6cc9eaa74e5a23f7/0.0.0/52cefbb2b82b015d4253f1aeb1e6ee5591124a6491e834acfe1751f765925155. Subsequent calls will reuse this data.\n",
      "CPU times: user 356 ms, sys: 40 ms, total: 396 ms\n",
      "Wall time: 1.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = load_dataset(\"text\", data_files={\"train\": train_files, \"test\": dev_files}, split=[\"train\", \"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affa5848f7c64a128843ed4759791c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2772.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d508b5bf3ceb43a58a93fd7f6296b478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=879.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "batch_size = 48\n",
    "\n",
    "eval_batch_size = 16\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=batch_size)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=eval_batch_size)\n",
    "#dev_dataset = dev_dataset.map(tokenize, batched=True, batch_size=eval_batch_size)\n",
    "#test_dataset = test_dataset.map(tokenize, batched=True, batch_size=eval_batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about lengths of tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.1752e+04, 4.0037e+04, 1.1234e+04, 4.4810e+03, 2.9270e+03,\n",
       "        2.0020e+03, 4.9000e+02, 6.9000e+01, 1.4000e+01, 3.1000e+01]),\n",
       " array([  2. ,  14.6,  27.2,  39.8,  52.4,  65. ,  77.6,  90.2, 102.8,\n",
       "        115.4, 128. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lens = [sum(t[\"attention_mask\"]) for t in train_dataset]\n",
    "\n",
    "plt.hist(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "128 should do the trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/transformers/trainer.py:277: FutureWarning: Passing `prediction_loss_only` as a keyword argument is deprecated and won't be possible in a future version. Use `args.prediction_loss_only` instead. Setting `args.prediction_loss_only=True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "model_name = \"TwiBETO-general\"\n",
    "\n",
    "model_path = f\"./{model_name}\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_path,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=30,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1500,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    save_steps=2000,\n",
    "    logging_steps=50,\n",
    "    do_eval= True,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='4540' max='41580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4540/41580 1:41:26 < 13:48:03, 0.75 it/s, Epoch 3.27/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.496255</td>\n",
       "      <td>3.228600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.345537</td>\n",
       "      <td>3.203470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.237148</td>\n",
       "      <td>3.189625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    773\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1124\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./TwiBETO-general/tokenizer_config.json',\n",
       " './TwiBETO-general/special_tokens_map.json',\n",
       " './TwiBETO-general/vocab.txt',\n",
       " './TwiBETO-general/added_tokens.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ../models/TwiBETO-general/checkpoint-2000/ and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = 'dccuchile/bert-base-spanish-wwm-cased'\n",
    "\n",
    "fill_mask_beto = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=model_name,\n",
    "    tokenizer=model_name\n",
    ")\n",
    "\n",
    "fill_mask_twibeto = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"../models/TwiBETO-general/\",\n",
    "    tokenizer=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '[CLS] la capital de Rusia es Rusia [SEP]',\n",
       "  'score': 0.07089567929506302,\n",
       "  'token': 5298,\n",
       "  'token_str': 'Rusia'},\n",
       " {'sequence': '[CLS] la capital de Rusia es Moscú [SEP]',\n",
       "  'score': 0.04152743145823479,\n",
       "  'token': 11487,\n",
       "  'token_str': 'Moscú'},\n",
       " {'sequence': '[CLS] la capital de Rusia es Madrid [SEP]',\n",
       "  'score': 0.021272020414471626,\n",
       "  'token': 5233,\n",
       "  'token_str': 'Madrid'},\n",
       " {'sequence': '[CLS] la capital de Rusia es usuario [SEP]',\n",
       "  'score': 0.019806960597634315,\n",
       "  'token': 9127,\n",
       "  'token_str': 'usuario'},\n",
       " {'sequence': '[CLS] la capital de Rusia es España [SEP]',\n",
       "  'score': 0.01951727829873562,\n",
       "  'token': 3229,\n",
       "  'token_str': 'España'}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = \"la capital de Rusia es [MASK]\"\n",
    "\n",
    "targets = None\n",
    "fill_mask_twibeto(phrase, targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '[CLS] la capital de España es : [SEP]',\n",
       "  'score': 0.3050116002559662,\n",
       "  'token': 1181,\n",
       "  'token_str': ':'},\n",
       " {'sequence': '[CLS] la capital de España es Madrid [SEP]',\n",
       "  'score': 0.13494569063186646,\n",
       "  'token': 5233,\n",
       "  'token_str': 'Madrid'},\n",
       " {'sequence': '[CLS] la capital de España es. [SEP]',\n",
       "  'score': 0.12530945241451263,\n",
       "  'token': 1009,\n",
       "  'token_str': '.'},\n",
       " {'sequence': '[CLS] la capital de España es [UNK] [SEP]',\n",
       "  'score': 0.05696418881416321,\n",
       "  'token': 3,\n",
       "  'token_str': '[UNK]'},\n",
       " {'sequence': '[CLS] la capital de España es Sevilla [SEP]',\n",
       "  'score': 0.04788172245025635,\n",
       "  'token': 12332,\n",
       "  'token_str': 'Sevilla'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask_beto(phrase, targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mask_beto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
