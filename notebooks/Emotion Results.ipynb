{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../evaluations/emotion_bertweet_base.json\n",
      "../evaluations/emotion_beto.json\n",
      "../evaluations/emotion_mbert_es.json\n",
      "../evaluations/emotion_roberta.json\n",
      "../evaluations/emotion_bert_base.json\n",
      "../evaluations/emotion_distilbert_es.json\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import glob \n",
    "import json \n",
    "\n",
    "evaluation_files = glob.glob(\"../evaluations/emotion_*.json\")\n",
    "\n",
    "evaluations = []\n",
    "\n",
    "for file in evaluation_files:\n",
    "    print(file)\n",
    "    with open(file) as f:\n",
    "        evaluation = json.load(f)\n",
    "        evaluation[\"file\"] = file.split(\"/\")[-1]\n",
    "        evaluations.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Lang</th>\n      <th>Loss</th>\n      <th>Others f1</th>\n      <th>Others precision</th>\n      <th>Others recall</th>\n      <th>Joy f1</th>\n      <th>Joy precision</th>\n      <th>Joy recall</th>\n      <th>Sadness f1</th>\n      <th>...</th>\n      <th>Disgust recall</th>\n      <th>Fear f1</th>\n      <th>Fear precision</th>\n      <th>Fear recall</th>\n      <th>Macro f1</th>\n      <th>Macro precision</th>\n      <th>Macro recall</th>\n      <th>Acc</th>\n      <th>Runtime</th>\n      <th>Samples per second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>bert-base</td>\n      <td>en</td>\n      <td>1.448668</td>\n      <td>0.660011</td>\n      <td>0.609007</td>\n      <td>0.720339</td>\n      <td>0.680121</td>\n      <td>0.700624</td>\n      <td>0.660784</td>\n      <td>0.565445</td>\n      <td>...</td>\n      <td>0.371728</td>\n      <td>0.253968</td>\n      <td>0.320000</td>\n      <td>0.210526</td>\n      <td>0.441858</td>\n      <td>0.486801</td>\n      <td>0.415784</td>\n      <td>0.601862</td>\n      <td>15.6117</td>\n      <td>116.964</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>bertweet-base</td>\n      <td>en</td>\n      <td>1.188743</td>\n      <td>0.663127</td>\n      <td>0.646720</td>\n      <td>0.680387</td>\n      <td>0.711198</td>\n      <td>0.712598</td>\n      <td>0.709804</td>\n      <td>0.582960</td>\n      <td>...</td>\n      <td>0.486911</td>\n      <td>0.166667</td>\n      <td>0.400000</td>\n      <td>0.105263</td>\n      <td>0.459780</td>\n      <td>0.497312</td>\n      <td>0.452507</td>\n      <td>0.618291</td>\n      <td>15.1347</td>\n      <td>120.650</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>roberta-base</td>\n      <td>en</td>\n      <td>1.182252</td>\n      <td>0.650000</td>\n      <td>0.654791</td>\n      <td>0.645278</td>\n      <td>0.722800</td>\n      <td>0.698355</td>\n      <td>0.749020</td>\n      <td>0.564315</td>\n      <td>...</td>\n      <td>0.549738</td>\n      <td>0.273973</td>\n      <td>0.285714</td>\n      <td>0.263158</td>\n      <td>0.473204</td>\n      <td>0.502806</td>\n      <td>0.471303</td>\n      <td>0.620482</td>\n      <td>14.9586</td>\n      <td>122.070</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>distilbert-es</td>\n      <td>es</td>\n      <td>1.096623</td>\n      <td>0.735577</td>\n      <td>0.731183</td>\n      <td>0.740024</td>\n      <td>0.589849</td>\n      <td>0.585831</td>\n      <td>0.593923</td>\n      <td>0.707617</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.564103</td>\n      <td>0.523810</td>\n      <td>0.611111</td>\n      <td>0.477111</td>\n      <td>0.492448</td>\n      <td>0.487962</td>\n      <td>0.652355</td>\n      <td>8.1527</td>\n      <td>205.698</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mbert-es</td>\n      <td>es</td>\n      <td>1.138236</td>\n      <td>0.737153</td>\n      <td>0.720554</td>\n      <td>0.754534</td>\n      <td>0.591281</td>\n      <td>0.583333</td>\n      <td>0.599448</td>\n      <td>0.696682</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.606061</td>\n      <td>0.666667</td>\n      <td>0.555556</td>\n      <td>0.487876</td>\n      <td>0.514672</td>\n      <td>0.479579</td>\n      <td>0.655337</td>\n      <td>8.7886</td>\n      <td>190.815</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>beto</td>\n      <td>es</td>\n      <td>1.216769</td>\n      <td>0.762615</td>\n      <td>0.725191</td>\n      <td>0.804111</td>\n      <td>0.639087</td>\n      <td>0.660767</td>\n      <td>0.618785</td>\n      <td>0.756892</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.511628</td>\n      <td>0.440000</td>\n      <td>0.611111</td>\n      <td>0.500856</td>\n      <td>0.507610</td>\n      <td>0.505274</td>\n      <td>0.688730</td>\n      <td>13.9726</td>\n      <td>120.021</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows Ã— 30 columns</p>\n</div>",
      "text/plain": "           Model Lang      Loss  Others f1  Others precision  Others recall  \\\n4      bert-base   en  1.448668   0.660011          0.609007       0.720339   \n0  bertweet-base   en  1.188743   0.663127          0.646720       0.680387   \n3   roberta-base   en  1.182252   0.650000          0.654791       0.645278   \n5  distilbert-es   es  1.096623   0.735577          0.731183       0.740024   \n2       mbert-es   es  1.138236   0.737153          0.720554       0.754534   \n1           beto   es  1.216769   0.762615          0.725191       0.804111   \n\n     Joy f1  Joy precision  Joy recall  Sadness f1  ...  Disgust recall  \\\n4  0.680121       0.700624    0.660784    0.565445  ...        0.371728   \n0  0.711198       0.712598    0.709804    0.582960  ...        0.486911   \n3  0.722800       0.698355    0.749020    0.564315  ...        0.549738   \n5  0.589849       0.585831    0.593923    0.707617  ...        0.000000   \n2  0.591281       0.583333    0.599448    0.696682  ...        0.000000   \n1  0.639087       0.660767    0.618785    0.756892  ...        0.000000   \n\n    Fear f1  Fear precision  Fear recall  Macro f1  Macro precision  \\\n4  0.253968        0.320000     0.210526  0.441858         0.486801   \n0  0.166667        0.400000     0.105263  0.459780         0.497312   \n3  0.273973        0.285714     0.263158  0.473204         0.502806   \n5  0.564103        0.523810     0.611111  0.477111         0.492448   \n2  0.606061        0.666667     0.555556  0.487876         0.514672   \n1  0.511628        0.440000     0.611111  0.500856         0.507610   \n\n   Macro recall       Acc  Runtime  Samples per second  \n4      0.415784  0.601862  15.6117             116.964  \n0      0.452507  0.618291  15.1347             120.650  \n3      0.471303  0.620482  14.9586             122.070  \n5      0.487962  0.652355   8.1527             205.698  \n2      0.479579  0.655337   8.7886             190.815  \n1      0.505274  0.688730  13.9726             120.021  \n\n[6 rows x 30 columns]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {**evaluation, **evaluation[\"metrics\"]} for evaluation in evaluations\n",
    "])\n",
    "\n",
    "df.drop(labels=[\"predictions\", \"labels\", \"metrics\", \"file\"], inplace=True, axis=1)\n",
    "df[\"model\"] = df[\"model\"].str.replace(\"models/\", \"\")\n",
    "df[\"model\"] = df[\"model\"].str.replace(\"-emotion-analysis/\", \"\")\n",
    "df.columns = [col.replace(\"test_\", \"\").replace(\"_\", \" \").capitalize() for col in df.columns]\n",
    "#df.set_index(\"Model\", inplace=True)\n",
    "df = df.sort_values([\"Lang\", \"Macro f1\"]) \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrrrr}\n",
      "\\toprule\n",
      "        Model & Lang &  Others f1 &  Joy f1 &  Sadness f1 &  Anger f1 &  Surprise f1 &  Disgust f1 &  Fear f1 &  Macro f1 \\\\\n",
      "\\midrule\n",
      "    bert-base &   en &      0.660 &   0.680 &       0.565 &     0.299 &        0.233 &       0.401 &    0.254 &     0.442 \\\\\n",
      "bertweet-base &   en &      0.663 &   0.711 &       0.583 &     0.312 &        0.305 &       0.477 &    0.167 &     0.460 \\\\\n",
      " roberta-base &   en &      0.650 &   0.723 &       0.564 &     0.329 &        0.258 &       0.515 &    0.274 &     0.473 \\\\\n",
      "distilbert-es &   es &      0.736 &   0.590 &       0.708 &     0.520 &        0.222 &       0.000 &    0.564 &     0.477 \\\\\n",
      "     mbert-es &   es &      0.737 &   0.591 &       0.697 &     0.513 &        0.271 &       0.000 &    0.606 &     0.488 \\\\\n",
      "         beto &   es &      0.763 &   0.639 &       0.757 &     0.558 &        0.278 &       0.000 &    0.512 &     0.501 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_columns = [col for col in df.columns if \"f1\" in col and \"Macro\" not in col]\n",
    "print(df[[\"Model\", \"Lang\"] + f1_columns + [\"Macro f1\"]].to_latex(index=False, float_format=\"{0:.3f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pysent-oyXQVI9B': pipenv)",
   "name": "python385jvsc74a57bd01b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "1b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}