{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LSTM model\n",
    "\n",
    "In this notebook we will train a LSTM model for Sentiment Analysis in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4802 2443 7264\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset, Value, ClassLabel, Features\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "from pysentimiento.tass import load_datasets\n",
    "\n",
    "\n",
    "train_dataset, dev_dataset, test_dataset = load_datasets(preprocess_args={\n",
    "    \"user_token\": \"USUARIO\",\n",
    "    \"url_token\": \"URL\",\n",
    "    \"hashtag_token\": \"hashtag\",\n",
    "    \"emoji_wrapper\": \"\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23513"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "import unidecode\n",
    "\n",
    "tokenizer = get_tokenizer(\"spacy\", \"es_core_news_sm\")\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "\"\"\"\n",
    "No overfitting, just taking the embeddings\n",
    "\"\"\"\n",
    "for dataset in [train_dataset, dev_dataset, test_dataset]:\n",
    "    for example in dataset:\n",
    "        tokens = tokenizer(unidecode.unidecode(example[\"text\"].lower()))\n",
    "        counter.update(tokens)\n",
    "\n",
    "# Meto todas\n",
    "vocab = Vocab(counter, min_freq=1)\n",
    "\n",
    "len(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cd01a3c23a4badaa6950babc035359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4802.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4570c16a14774b359b50782b3789aaee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2443.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a148b19f9b4f81b135bf653a7227bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7264.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tokenize(batch):\n",
    "    text = unidecode.unidecode(batch['text'].lower())\n",
    "    tokens = tokenizer(text)\n",
    "    token_ids = [vocab.stoi[t] for t in tokens]\n",
    "    return {\"input_ids\": token_ids}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "eval_batch_size = 16\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=False)\n",
    "dev_dataset = dev_dataset.map(tokenize, batched=False)\n",
    "test_dataset = test_dataset.map(tokenize, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d066a1f8e94d998b2dd636da5d4b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4802.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff8ccf096f446f28c9b7d7484aa9360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2443.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4051b8d59dd745f49fbc7c4b147e1da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7264.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def format_dataset(dataset):\n",
    "    dataset = dataset.map(lambda examples: {'labels': examples['label']})\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'labels'])\n",
    "    return dataset\n",
    "\n",
    "train_dataset = format_dataset(train_dataset)\n",
    "dev_dataset = format_dataset(dev_dataset)\n",
    "test_dataset = format_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fasttext\n",
    "\n",
    "fasttext_model = fasttext.load_model(\"../../embeddings/cc.es.300.bin\")\n",
    "\n",
    "\n",
    "DIM = fasttext_model.get_word_vector(\"random\").shape[0]\n",
    "emb_matrix = torch.randn(len(vocab), DIM)\n",
    "UNK_IDX = vocab.stoi[\"<unk>\"]\n",
    "PAD_IDX = vocab.stoi[\"<pad>\"]\n",
    "\n",
    "# emb_matrix[UNK_IDX] = 0\n",
    "emb_matrix[PAD_IDX] = 0\n",
    "\n",
    "for i, word in enumerate(vocab.itos):\n",
    "    if i == UNK_IDX or i == PAD_IDX:\n",
    "        # Let them unmodified\n",
    "        pass\n",
    "    else:\n",
    "        emb_matrix[i] = torch.tensor(fasttext_model.get_word_vector(word))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "PAD_IDX = vocab.stoi[\"<pad>\"]\n",
    "\n",
    "def collate_batch(batch):\n",
    "    labels = [t[\"labels\"] for t in batch]\n",
    "    input_ids = [t[\"input_ids\"] for t in batch]\n",
    "\n",
    "    # Return text, text_lens, labels\n",
    "    return pad_sequence(input_ids, padding_value=PAD_IDX, batch_first=True), torch.tensor([len(t) for t in input_ids]), torch.tensor(labels)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_batch)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=16, collate_fn=collate_batch)\n",
    "test_dataset = DataLoader(test_dataset, batch_size=16, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from pysentimiento.tass import id2label\n",
    "from pysentimiento.metrics import get_metrics\n",
    "from torch import nn\n",
    "\n",
    "class RNNModel(pl.LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dim, pad_idx, rnn_units, num_labels, num_layers=1,\n",
    "                 bidirectional=False, dropout=0.25, embedding_matrix=None, freeze_embeddings=True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                embedding_matrix, padding_idx=pad_idx,\n",
    "                freeze=freeze_embeddings\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(\n",
    "                vocab_size, embedding_dim,\n",
    "                padding_idx = pad_idx)\n",
    "\n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                   rnn_units,\n",
    "                   num_layers=num_layers,\n",
    "                   bidirectional=bidirectional, batch_first=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        factor = 2 if bidirectional else 1\n",
    "\n",
    "        self.fc = nn.Linear(rnn_units * factor, num_labels)\n",
    "\n",
    "    def forward(self, text, text_lens):\n",
    "        #text = [batch_size, text len]\n",
    "        #permuted = text.permute(1, 0)\n",
    "        # permuted shape [batch_size, sent len]\n",
    "        embedded = self.embedding(text)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
    "            # WTF no sé por qué hago esto de cpu\n",
    "            embedded, text_lens.to(\"cpu\"), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        packed_output, _ = self.rnn(packed_embedded)\n",
    "        # hidden is the last state of the\n",
    "\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        # output is shape [seq, batch, hid]\n",
    "        s = output.permute(1, 0, 2)\n",
    "        # now [batch, seq, hid]\n",
    "        mean = s.sum(dim=1) / text_lens.view(-1, 1)\n",
    "\n",
    "        return self.fc(mean)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, lens, y = batch\n",
    "        outs = self.forward(x, lens)\n",
    "        loss = F.cross_entropy(outs, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, lens, y = batch\n",
    "        outs = self.forward(x, lens)\n",
    "        loss = F.cross_entropy(outs, y)\n",
    "        preds = outs.argmax(-1).cpu()\n",
    "        metrics = get_metrics(preds, y.cpu(), id2label)\n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        for k, v in metrics.items():\n",
    "            self.log(k, v, prog_bar=True, on_epoch=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | embedding | Embedding | 7.1 M \n",
      "1 | rnn       | GRU       | 428 K \n",
      "2 | dropout   | Dropout   | 0     \n",
      "3 | fc        | Linear    | 771   \n",
      "----------------------------------------\n",
      "429 K     Trainable params\n",
      "7.1 M     Non-trainable params\n",
      "7.5 M     Total params\n",
      "29.933    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf84ffc658d42b4a6963387c3c5de3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8654f440254c40a805c1afe14be6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19f8b1d57364da49cf6684b2fd91883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/pysent-oyXQVI9B/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:610: LightningDeprecationWarning: Relying on `self.log('val_loss', ...)` to set the ModelCheckpoint monitor is deprecated in v1.2 and will be removed in v1.4. Please, create your own `mc = ModelCheckpoint(monitor='your_monitor')` and use it as `Trainer(callbacks=[mc])`.\n",
      "  warning_cache.deprecation(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55691c8f699428291df5cab3ec6a493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f3fe42882549afb89ef3a54c0356bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb47a1518954c0bb2ee8f1099c55a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693574c3bcfa4de4b5e8d6616d56b678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6ce32aacfc4311966d6a86f92cd427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2e4538f4ce41c0acbfb5644fcfe9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928e5b98ef49476087574c8f47af493e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f148efddb349eabfc8eac1e4902ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9311123c6f214180a1f1f13a3f27b088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = RNNModel(\n",
    "    vocab_size=len(vocab), embedding_dim=DIM, pad_idx=PAD_IDX, rnn_units=256, embedding_matrix=emb_matrix,\n",
    "    freeze_embeddings=True, num_labels=3,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10, \n",
    "    gpus=1\n",
    ")\n",
    "trainer.fit(model, train_dataloader, dev_dataloader)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pysent-oyXQVI9B': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "1b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}