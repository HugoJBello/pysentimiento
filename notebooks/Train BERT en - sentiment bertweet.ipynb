{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT model\n",
    "\n",
    "In this notebook we will train a BERT model for Sentiment Analysis in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39716 9929 20632\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset, Value, ClassLabel, Features\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "from pysentimiento.semeval import load_datasets\n",
    "\n",
    "\n",
    "train_dataset, dev_dataset, test_dataset = load_datasets(\n",
    "    preprocessing_args={\"user_token\": \"@USER\", \"url_token\": \"HTTPURL\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Loading model vinai/bertweet-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from pysentimiento.tass import load_model\n",
    "from pysentimiento.emotion.datasets import id2label, label2id\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "base_model = \"vinai/bertweet-base\"\n",
    "\n",
    "model, tokenizer = load_model(base_model, \n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae0b5ed34524bf9a15215412e97602d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1242.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983d382529b04311a569176b79ef8643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=621.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560d7a4e8c2c43b08278ec200f1bb63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1290.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "eval_batch_size = 16\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=batch_size)\n",
    "dev_dataset = dev_dataset.map(tokenize, batched=True, batch_size=eval_batch_size)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=eval_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fdcbb5272247bb8a97a71789e2a9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=39716.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d78cc3f854f4f14a507024c500b98b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=9929.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a0fd143ee649578cd23cade3e6de9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=20632.0), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def format_dataset(dataset):\n",
    "    dataset = dataset.map(lambda examples: {'labels': examples['label']})\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "    return dataset\n",
    "\n",
    "train_dataset = format_dataset(train_dataset)\n",
    "dev_dataset = format_dataset(dev_dataset)\n",
    "test_dataset = format_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.select(range(2000))\n",
    "dev_dataset = dev_dataset.select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 02:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Neg F1</th>\n      <th>Neg Precision</th>\n      <th>Neg Recall</th>\n      <th>Neu F1</th>\n      <th>Neu Precision</th>\n      <th>Neu Recall</th>\n      <th>Pos F1</th>\n      <th>Pos Precision</th>\n      <th>Pos Recall</th>\n      <th>Macro F1</th>\n      <th>Macro Precision</th>\n      <th>Macro Recall</th>\n      <th>Acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.825749</td>\n      <td>0.081395</td>\n      <td>1.000000</td>\n      <td>0.042424</td>\n      <td>0.681954</td>\n      <td>0.596859</td>\n      <td>0.795349</td>\n      <td>0.753939</td>\n      <td>0.740476</td>\n      <td>0.767901</td>\n      <td>0.505763</td>\n      <td>0.779112</td>\n      <td>0.535225</td>\n      <td>0.660000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.738455</td>\n      <td>0.620253</td>\n      <td>0.649007</td>\n      <td>0.593939</td>\n      <td>0.649874</td>\n      <td>0.708791</td>\n      <td>0.600000</td>\n      <td>0.759551</td>\n      <td>0.696907</td>\n      <td>0.834568</td>\n      <td>0.676559</td>\n      <td>0.684902</td>\n      <td>0.676169</td>\n      <td>0.694000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.738773</td>\n      <td>0.639053</td>\n      <td>0.624277</td>\n      <td>0.654545</td>\n      <td>0.658625</td>\n      <td>0.684211</td>\n      <td>0.634884</td>\n      <td>0.753902</td>\n      <td>0.733645</td>\n      <td>0.775309</td>\n      <td>0.683860</td>\n      <td>0.680711</td>\n      <td>0.688246</td>\n      <td>0.695000</td>\n    </tr>\n  </tbody>\n</table><p>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=189, training_loss=0.8189254034133184, metrics={'train_runtime': 120.4721, 'train_samples_per_second': 1.569, 'total_flos': 0, 'epoch': 3.0})"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from pysentimiento.metrics import compute_metrics\n",
    "from pysentimiento.semeval.datasets import id2label\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "total_steps = (epochs * len(train_dataset)) // batch_size\n",
    "warmup_steps = total_steps // 10\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    warmup_steps=warmup_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    do_eval=False,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=lambda x: compute_metrics(x, id2label=id2label),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n    <div>\n      \n      <progress value='1290' max='1290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1290/1290 01:50]\n    </div>\n    ",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.7367324233055115,\n 'eval_neg_f1': 0.6306330837304288,\n 'eval_neg_precision': 0.5629557608167234,\n 'eval_neg_recall': 0.7168059424326834,\n 'eval_neu_f1': 0.6978179882916445,\n 'eval_neu_precision': 0.7760416666666666,\n 'eval_neu_recall': 0.6339199381164184,\n 'eval_pos_f1': 0.7457201401282305,\n 'eval_pos_precision': 0.6990086741016109,\n 'eval_pos_recall': 0.7991216886244511,\n 'eval_macro_f1': 0.691390335559845,\n 'eval_macro_precision': 0.679335355758667,\n 'eval_macro_recall': 0.7166158556938171,\n 'eval_acc': 0.7034218689414502,\n 'eval_runtime': 110.237,\n 'eval_samples_per_second': 187.16,\n 'epoch': 3.0}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pysent-oyXQVI9B': pipenv)",
   "name": "python385jvsc74a57bd01b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "1b2ee3c7e4be117f16044e4287774c113d04cbc1cc9e7e3b16e6e098f73486a4"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}